// Generated by the protocol buffer compiler.  DO NOT EDIT!
// NO CHECKED-IN PROTOBUF GENCODE
// source: metadata/v1/metadata.proto
// Protobuf Java Version: 4.29.3

package io.confluent.kafka.schemaregistry.storage.encoder;

/**
 * Protobuf type {@code metadata.v1.MetadataKeysetWrapperList}
 */
public final class MetadataKeysetWrapperList extends
        com.google.protobuf.GeneratedMessage implements
        // @@protoc_insertion_point(message_implements:metadata.v1.MetadataKeysetWrapperList)
        MetadataKeysetWrapperListOrBuilder {
  private static final long serialVersionUID = 0L;
  static {
    com.google.protobuf.RuntimeVersion.validateProtobufGencodeVersion(
            com.google.protobuf.RuntimeVersion.RuntimeDomain.PUBLIC,
            /* major= */ 4,
            /* minor= */ 29,
            /* patch= */ 3,
            /* suffix= */ "",
            MetadataKeysetWrapperList.class.getName());
  }
  // Use MetadataKeysetWrapperList.newBuilder() to construct.
  private MetadataKeysetWrapperList(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
    super(builder);
  }
  private MetadataKeysetWrapperList() {
    items_ = java.util.Collections.emptyList();
  }

  public static final com.google.protobuf.Descriptors.Descriptor
  getDescriptor() {
    return io.confluent.kafka.schemaregistry.storage.encoder.Metadata.internal_static_metadata_v1_MetadataKeysetWrapperList_descriptor;
  }

  @java.lang.Override
  protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
  internalGetFieldAccessorTable() {
    return io.confluent.kafka.schemaregistry.storage.encoder.Metadata.internal_static_metadata_v1_MetadataKeysetWrapperList_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                    io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList.class, io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList.Builder.class);
  }

  private int bitField0_;
  public static final int METADATA_FIELD_NUMBER = 1;
  private io.confluent.resourcemanager.protobuf.apis.meta.v1.ListMeta metadata_;
  /**
   * <code>.resourcemanager.meta.v1.ListMeta metadata = 1;</code>
   * @return Whether the metadata field is set.
   */
  @java.lang.Override
  public boolean hasMetadata() {
    return ((bitField0_ & 0x00000001) != 0);
  }
  /**
   * <code>.resourcemanager.meta.v1.ListMeta metadata = 1;</code>
   * @return The metadata.
   */
  @java.lang.Override
  public io.confluent.resourcemanager.protobuf.apis.meta.v1.ListMeta getMetadata() {
    return metadata_ == null ? io.confluent.resourcemanager.protobuf.apis.meta.v1.ListMeta.getDefaultInstance() : metadata_;
  }
  /**
   * <code>.resourcemanager.meta.v1.ListMeta metadata = 1;</code>
   */
  @java.lang.Override
  public io.confluent.resourcemanager.protobuf.apis.meta.v1.ListMetaOrBuilder getMetadataOrBuilder() {
    return metadata_ == null ? io.confluent.resourcemanager.protobuf.apis.meta.v1.ListMeta.getDefaultInstance() : metadata_;
  }

  public static final int ITEMS_FIELD_NUMBER = 2;
  @SuppressWarnings("serial")
  private java.util.List<io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper> items_;
  /**
   * <code>repeated .metadata.v1.MetadataKeysetWrapper items = 2;</code>
   */
  @java.lang.Override
  public java.util.List<io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper> getItemsList() {
    return items_;
  }
  /**
   * <code>repeated .metadata.v1.MetadataKeysetWrapper items = 2;</code>
   */
  @java.lang.Override
  public java.util.List<? extends io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperOrBuilder>
  getItemsOrBuilderList() {
    return items_;
  }
  /**
   * <code>repeated .metadata.v1.MetadataKeysetWrapper items = 2;</code>
   */
  @java.lang.Override
  public int getItemsCount() {
    return items_.size();
  }
  /**
   * <code>repeated .metadata.v1.MetadataKeysetWrapper items = 2;</code>
   */
  @java.lang.Override
  public io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper getItems(int index) {
    return items_.get(index);
  }
  /**
   * <code>repeated .metadata.v1.MetadataKeysetWrapper items = 2;</code>
   */
  @java.lang.Override
  public io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperOrBuilder getItemsOrBuilder(
          int index) {
    return items_.get(index);
  }

  private byte memoizedIsInitialized = -1;
  @java.lang.Override
  public final boolean isInitialized() {
    byte isInitialized = memoizedIsInitialized;
    if (isInitialized == 1) return true;
    if (isInitialized == 0) return false;

    memoizedIsInitialized = 1;
    return true;
  }

  @java.lang.Override
  public void writeTo(com.google.protobuf.CodedOutputStream output)
          throws java.io.IOException {
    if (((bitField0_ & 0x00000001) != 0)) {
      output.writeMessage(1, getMetadata());
    }
    for (int i = 0; i < items_.size(); i++) {
      output.writeMessage(2, items_.get(i));
    }
    getUnknownFields().writeTo(output);
  }

  @java.lang.Override
  public int getSerializedSize() {
    int size = memoizedSize;
    if (size != -1) return size;

    size = 0;
    if (((bitField0_ & 0x00000001) != 0)) {
      size += com.google.protobuf.CodedOutputStream
              .computeMessageSize(1, getMetadata());
    }
    for (int i = 0; i < items_.size(); i++) {
      size += com.google.protobuf.CodedOutputStream
              .computeMessageSize(2, items_.get(i));
    }
    size += getUnknownFields().getSerializedSize();
    memoizedSize = size;
    return size;
  }

  @java.lang.Override
  public boolean equals(final java.lang.Object obj) {
    if (obj == this) {
      return true;
    }
    if (!(obj instanceof io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList)) {
      return super.equals(obj);
    }
    io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList other = (io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList) obj;

    if (hasMetadata() != other.hasMetadata()) return false;
    if (hasMetadata()) {
      if (!getMetadata()
              .equals(other.getMetadata())) return false;
    }
    if (!getItemsList()
            .equals(other.getItemsList())) return false;
    if (!getUnknownFields().equals(other.getUnknownFields())) return false;
    return true;
  }

  @java.lang.Override
  public int hashCode() {
    if (memoizedHashCode != 0) {
      return memoizedHashCode;
    }
    int hash = 41;
    hash = (19 * hash) + getDescriptor().hashCode();
    if (hasMetadata()) {
      hash = (37 * hash) + METADATA_FIELD_NUMBER;
      hash = (53 * hash) + getMetadata().hashCode();
    }
    if (getItemsCount() > 0) {
      hash = (37 * hash) + ITEMS_FIELD_NUMBER;
      hash = (53 * hash) + getItemsList().hashCode();
    }
    hash = (29 * hash) + getUnknownFields().hashCode();
    memoizedHashCode = hash;
    return hash;
  }

  public static io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList parseFrom(
          java.nio.ByteBuffer data)
          throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList parseFrom(
          java.nio.ByteBuffer data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList parseFrom(java.io.InputStream input)
          throws java.io.IOException {
    return com.google.protobuf.GeneratedMessage
            .parseWithIOException(PARSER, input);
  }
  public static io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
    return com.google.protobuf.GeneratedMessage
            .parseWithIOException(PARSER, input, extensionRegistry);
  }

  public static io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
    return com.google.protobuf.GeneratedMessage
            .parseDelimitedWithIOException(PARSER, input);
  }

  public static io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
    return com.google.protobuf.GeneratedMessage
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
  }
  public static io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
    return com.google.protobuf.GeneratedMessage
            .parseWithIOException(PARSER, input);
  }
  public static io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
    return com.google.protobuf.GeneratedMessage
            .parseWithIOException(PARSER, input, extensionRegistry);
  }

  @java.lang.Override
  public Builder newBuilderForType() { return newBuilder(); }
  public static Builder newBuilder() {
    return DEFAULT_INSTANCE.toBuilder();
  }
  public static Builder newBuilder(io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList prototype) {
    return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
  }
  @java.lang.Override
  public Builder toBuilder() {
    return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
  }

  @java.lang.Override
  protected Builder newBuilderForType(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
    Builder builder = new Builder(parent);
    return builder;
  }
  /**
   * Protobuf type {@code metadata.v1.MetadataKeysetWrapperList}
   */
  public static final class Builder extends
          com.google.protobuf.GeneratedMessage.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:metadata.v1.MetadataKeysetWrapperList)
          io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperListOrBuilder {
    public static final com.google.protobuf.Descriptors.Descriptor
    getDescriptor() {
      return io.confluent.kafka.schemaregistry.storage.encoder.Metadata.internal_static_metadata_v1_MetadataKeysetWrapperList_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
    internalGetFieldAccessorTable() {
      return io.confluent.kafka.schemaregistry.storage.encoder.Metadata.internal_static_metadata_v1_MetadataKeysetWrapperList_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                      io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList.class, io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList.Builder.class);
    }

    // Construct using io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList.newBuilder()
    private Builder() {
      maybeForceBuilderInitialization();
    }

    private Builder(
            com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      super(parent);
      maybeForceBuilderInitialization();
    }
    private void maybeForceBuilderInitialization() {
      if (com.google.protobuf.GeneratedMessage
              .alwaysUseFieldBuilders) {
        getMetadataFieldBuilder();
        getItemsFieldBuilder();
      }
    }
    @java.lang.Override
    public Builder clear() {
      super.clear();
      bitField0_ = 0;
      metadata_ = null;
      if (metadataBuilder_ != null) {
        metadataBuilder_.dispose();
        metadataBuilder_ = null;
      }
      if (itemsBuilder_ == null) {
        items_ = java.util.Collections.emptyList();
      } else {
        items_ = null;
        itemsBuilder_.clear();
      }
      bitField0_ = (bitField0_ & ~0x00000002);
      return this;
    }

    @java.lang.Override
    public com.google.protobuf.Descriptors.Descriptor
    getDescriptorForType() {
      return io.confluent.kafka.schemaregistry.storage.encoder.Metadata.internal_static_metadata_v1_MetadataKeysetWrapperList_descriptor;
    }

    @java.lang.Override
    public io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList getDefaultInstanceForType() {
      return io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList.getDefaultInstance();
    }

    @java.lang.Override
    public io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList build() {
      io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList result = buildPartial();
      if (!result.isInitialized()) {
        throw newUninitializedMessageException(result);
      }
      return result;
    }

    @java.lang.Override
    public io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList buildPartial() {
      io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList result = new io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList(this);
      buildPartialRepeatedFields(result);
      if (bitField0_ != 0) { buildPartial0(result); }
      onBuilt();
      return result;
    }

    private void buildPartialRepeatedFields(io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList result) {
      if (itemsBuilder_ == null) {
        if (((bitField0_ & 0x00000002) != 0)) {
          items_ = java.util.Collections.unmodifiableList(items_);
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.items_ = items_;
      } else {
        result.items_ = itemsBuilder_.build();
      }
    }

    private void buildPartial0(io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList result) {
      int from_bitField0_ = bitField0_;
      int to_bitField0_ = 0;
      if (((from_bitField0_ & 0x00000001) != 0)) {
        result.metadata_ = metadataBuilder_ == null
                ? metadata_
                : metadataBuilder_.build();
        to_bitField0_ |= 0x00000001;
      }
      result.bitField0_ |= to_bitField0_;
    }

    @java.lang.Override
    public Builder mergeFrom(com.google.protobuf.Message other) {
      if (other instanceof io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList) {
        return mergeFrom((io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList)other);
      } else {
        super.mergeFrom(other);
        return this;
      }
    }

    public Builder mergeFrom(io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList other) {
      if (other == io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList.getDefaultInstance()) return this;
      if (other.hasMetadata()) {
        mergeMetadata(other.getMetadata());
      }
      if (itemsBuilder_ == null) {
        if (!other.items_.isEmpty()) {
          if (items_.isEmpty()) {
            items_ = other.items_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureItemsIsMutable();
            items_.addAll(other.items_);
          }
          onChanged();
        }
      } else {
        if (!other.items_.isEmpty()) {
          if (itemsBuilder_.isEmpty()) {
            itemsBuilder_.dispose();
            itemsBuilder_ = null;
            items_ = other.items_;
            bitField0_ = (bitField0_ & ~0x00000002);
            itemsBuilder_ =
                    com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                            getItemsFieldBuilder() : null;
          } else {
            itemsBuilder_.addAllMessages(other.items_);
          }
        }
      }
      this.mergeUnknownFields(other.getUnknownFields());
      onChanged();
      return this;
    }

    @java.lang.Override
    public final boolean isInitialized() {
      return true;
    }

    @java.lang.Override
    public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              input.readMessage(
                      getMetadataFieldBuilder().getBuilder(),
                      extensionRegistry);
              bitField0_ |= 0x00000001;
              break;
            } // case 10
            case 18: {
              io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper m =
                      input.readMessage(
                              io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper.parser(),
                              extensionRegistry);
              if (itemsBuilder_ == null) {
                ensureItemsIsMutable();
                items_.add(m);
              } else {
                itemsBuilder_.addMessage(m);
              }
              break;
            } // case 18
            default: {
              if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                done = true; // was an endgroup tag
              }
              break;
            } // default:
          } // switch (tag)
        } // while (!done)
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.unwrapIOException();
      } finally {
        onChanged();
      } // finally
      return this;
    }
    private int bitField0_;

    private io.confluent.resourcemanager.protobuf.apis.meta.v1.ListMeta metadata_;
    private com.google.protobuf.SingleFieldBuilder<
            io.confluent.resourcemanager.protobuf.apis.meta.v1.ListMeta, io.confluent.resourcemanager.protobuf.apis.meta.v1.ListMeta.Builder, io.confluent.resourcemanager.protobuf.apis.meta.v1.ListMetaOrBuilder> metadataBuilder_;
    /**
     * <code>.resourcemanager.meta.v1.ListMeta metadata = 1;</code>
     * @return Whether the metadata field is set.
     */
    public boolean hasMetadata() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>.resourcemanager.meta.v1.ListMeta metadata = 1;</code>
     * @return The metadata.
     */
    public io.confluent.resourcemanager.protobuf.apis.meta.v1.ListMeta getMetadata() {
      if (metadataBuilder_ == null) {
        return metadata_ == null ? io.confluent.resourcemanager.protobuf.apis.meta.v1.ListMeta.getDefaultInstance() : metadata_;
      } else {
        return metadataBuilder_.getMessage();
      }
    }
    /**
     * <code>.resourcemanager.meta.v1.ListMeta metadata = 1;</code>
     */
    public Builder setMetadata(io.confluent.resourcemanager.protobuf.apis.meta.v1.ListMeta value) {
      if (metadataBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        metadata_ = value;
      } else {
        metadataBuilder_.setMessage(value);
      }
      bitField0_ |= 0x00000001;
      onChanged();
      return this;
    }
    /**
     * <code>.resourcemanager.meta.v1.ListMeta metadata = 1;</code>
     */
    public Builder setMetadata(
            io.confluent.resourcemanager.protobuf.apis.meta.v1.ListMeta.Builder builderForValue) {
      if (metadataBuilder_ == null) {
        metadata_ = builderForValue.build();
      } else {
        metadataBuilder_.setMessage(builderForValue.build());
      }
      bitField0_ |= 0x00000001;
      onChanged();
      return this;
    }
    /**
     * <code>.resourcemanager.meta.v1.ListMeta metadata = 1;</code>
     */
    public Builder mergeMetadata(io.confluent.resourcemanager.protobuf.apis.meta.v1.ListMeta value) {
      if (metadataBuilder_ == null) {
        if (((bitField0_ & 0x00000001) != 0) &&
                metadata_ != null &&
                metadata_ != io.confluent.resourcemanager.protobuf.apis.meta.v1.ListMeta.getDefaultInstance()) {
          getMetadataBuilder().mergeFrom(value);
        } else {
          metadata_ = value;
        }
      } else {
        metadataBuilder_.mergeFrom(value);
      }
      if (metadata_ != null) {
        bitField0_ |= 0x00000001;
        onChanged();
      }
      return this;
    }
    /**
     * <code>.resourcemanager.meta.v1.ListMeta metadata = 1;</code>
     */
    public Builder clearMetadata() {
      bitField0_ = (bitField0_ & ~0x00000001);
      metadata_ = null;
      if (metadataBuilder_ != null) {
        metadataBuilder_.dispose();
        metadataBuilder_ = null;
      }
      onChanged();
      return this;
    }
    /**
     * <code>.resourcemanager.meta.v1.ListMeta metadata = 1;</code>
     */
    public io.confluent.resourcemanager.protobuf.apis.meta.v1.ListMeta.Builder getMetadataBuilder() {
      bitField0_ |= 0x00000001;
      onChanged();
      return getMetadataFieldBuilder().getBuilder();
    }
    /**
     * <code>.resourcemanager.meta.v1.ListMeta metadata = 1;</code>
     */
    public io.confluent.resourcemanager.protobuf.apis.meta.v1.ListMetaOrBuilder getMetadataOrBuilder() {
      if (metadataBuilder_ != null) {
        return metadataBuilder_.getMessageOrBuilder();
      } else {
        return metadata_ == null ?
                io.confluent.resourcemanager.protobuf.apis.meta.v1.ListMeta.getDefaultInstance() : metadata_;
      }
    }
    /**
     * <code>.resourcemanager.meta.v1.ListMeta metadata = 1;</code>
     */
    private com.google.protobuf.SingleFieldBuilder<
            io.confluent.resourcemanager.protobuf.apis.meta.v1.ListMeta, io.confluent.resourcemanager.protobuf.apis.meta.v1.ListMeta.Builder, io.confluent.resourcemanager.protobuf.apis.meta.v1.ListMetaOrBuilder>
    getMetadataFieldBuilder() {
      if (metadataBuilder_ == null) {
        metadataBuilder_ = new com.google.protobuf.SingleFieldBuilder<
                io.confluent.resourcemanager.protobuf.apis.meta.v1.ListMeta, io.confluent.resourcemanager.protobuf.apis.meta.v1.ListMeta.Builder, io.confluent.resourcemanager.protobuf.apis.meta.v1.ListMetaOrBuilder>(
                getMetadata(),
                getParentForChildren(),
                isClean());
        metadata_ = null;
      }
      return metadataBuilder_;
    }

    private java.util.List<io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper> items_ =
            java.util.Collections.emptyList();
    private void ensureItemsIsMutable() {
      if (!((bitField0_ & 0x00000002) != 0)) {
        items_ = new java.util.ArrayList<io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper>(items_);
        bitField0_ |= 0x00000002;
      }
    }

    private com.google.protobuf.RepeatedFieldBuilder<
            io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper, io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper.Builder, io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperOrBuilder> itemsBuilder_;

    /**
     * <code>repeated .metadata.v1.MetadataKeysetWrapper items = 2;</code>
     */
    public java.util.List<io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper> getItemsList() {
      if (itemsBuilder_ == null) {
        return java.util.Collections.unmodifiableList(items_);
      } else {
        return itemsBuilder_.getMessageList();
      }
    }
    /**
     * <code>repeated .metadata.v1.MetadataKeysetWrapper items = 2;</code>
     */
    public int getItemsCount() {
      if (itemsBuilder_ == null) {
        return items_.size();
      } else {
        return itemsBuilder_.getCount();
      }
    }
    /**
     * <code>repeated .metadata.v1.MetadataKeysetWrapper items = 2;</code>
     */
    public io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper getItems(int index) {
      if (itemsBuilder_ == null) {
        return items_.get(index);
      } else {
        return itemsBuilder_.getMessage(index);
      }
    }
    /**
     * <code>repeated .metadata.v1.MetadataKeysetWrapper items = 2;</code>
     */
    public Builder setItems(
            int index, io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper value) {
      if (itemsBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureItemsIsMutable();
        items_.set(index, value);
        onChanged();
      } else {
        itemsBuilder_.setMessage(index, value);
      }
      return this;
    }
    /**
     * <code>repeated .metadata.v1.MetadataKeysetWrapper items = 2;</code>
     */
    public Builder setItems(
            int index, io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper.Builder builderForValue) {
      if (itemsBuilder_ == null) {
        ensureItemsIsMutable();
        items_.set(index, builderForValue.build());
        onChanged();
      } else {
        itemsBuilder_.setMessage(index, builderForValue.build());
      }
      return this;
    }
    /**
     * <code>repeated .metadata.v1.MetadataKeysetWrapper items = 2;</code>
     */
    public Builder addItems(io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper value) {
      if (itemsBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureItemsIsMutable();
        items_.add(value);
        onChanged();
      } else {
        itemsBuilder_.addMessage(value);
      }
      return this;
    }
    /**
     * <code>repeated .metadata.v1.MetadataKeysetWrapper items = 2;</code>
     */
    public Builder addItems(
            int index, io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper value) {
      if (itemsBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureItemsIsMutable();
        items_.add(index, value);
        onChanged();
      } else {
        itemsBuilder_.addMessage(index, value);
      }
      return this;
    }
    /**
     * <code>repeated .metadata.v1.MetadataKeysetWrapper items = 2;</code>
     */
    public Builder addItems(
            io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper.Builder builderForValue) {
      if (itemsBuilder_ == null) {
        ensureItemsIsMutable();
        items_.add(builderForValue.build());
        onChanged();
      } else {
        itemsBuilder_.addMessage(builderForValue.build());
      }
      return this;
    }
    /**
     * <code>repeated .metadata.v1.MetadataKeysetWrapper items = 2;</code>
     */
    public Builder addItems(
            int index, io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper.Builder builderForValue) {
      if (itemsBuilder_ == null) {
        ensureItemsIsMutable();
        items_.add(index, builderForValue.build());
        onChanged();
      } else {
        itemsBuilder_.addMessage(index, builderForValue.build());
      }
      return this;
    }
    /**
     * <code>repeated .metadata.v1.MetadataKeysetWrapper items = 2;</code>
     */
    public Builder addAllItems(
            java.lang.Iterable<? extends io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper> values) {
      if (itemsBuilder_ == null) {
        ensureItemsIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
                values, items_);
        onChanged();
      } else {
        itemsBuilder_.addAllMessages(values);
      }
      return this;
    }
    /**
     * <code>repeated .metadata.v1.MetadataKeysetWrapper items = 2;</code>
     */
    public Builder clearItems() {
      if (itemsBuilder_ == null) {
        items_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
      } else {
        itemsBuilder_.clear();
      }
      return this;
    }
    /**
     * <code>repeated .metadata.v1.MetadataKeysetWrapper items = 2;</code>
     */
    public Builder removeItems(int index) {
      if (itemsBuilder_ == null) {
        ensureItemsIsMutable();
        items_.remove(index);
        onChanged();
      } else {
        itemsBuilder_.remove(index);
      }
      return this;
    }
    /**
     * <code>repeated .metadata.v1.MetadataKeysetWrapper items = 2;</code>
     */
    public io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper.Builder getItemsBuilder(
            int index) {
      return getItemsFieldBuilder().getBuilder(index);
    }
    /**
     * <code>repeated .metadata.v1.MetadataKeysetWrapper items = 2;</code>
     */
    public io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperOrBuilder getItemsOrBuilder(
            int index) {
      if (itemsBuilder_ == null) {
        return items_.get(index);  } else {
        return itemsBuilder_.getMessageOrBuilder(index);
      }
    }
    /**
     * <code>repeated .metadata.v1.MetadataKeysetWrapper items = 2;</code>
     */
    public java.util.List<? extends io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperOrBuilder>
    getItemsOrBuilderList() {
      if (itemsBuilder_ != null) {
        return itemsBuilder_.getMessageOrBuilderList();
      } else {
        return java.util.Collections.unmodifiableList(items_);
      }
    }
    /**
     * <code>repeated .metadata.v1.MetadataKeysetWrapper items = 2;</code>
     */
    public io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper.Builder addItemsBuilder() {
      return getItemsFieldBuilder().addBuilder(
              io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper.getDefaultInstance());
    }
    /**
     * <code>repeated .metadata.v1.MetadataKeysetWrapper items = 2;</code>
     */
    public io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper.Builder addItemsBuilder(
            int index) {
      return getItemsFieldBuilder().addBuilder(
              index, io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper.getDefaultInstance());
    }
    /**
     * <code>repeated .metadata.v1.MetadataKeysetWrapper items = 2;</code>
     */
    public java.util.List<io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper.Builder>
    getItemsBuilderList() {
      return getItemsFieldBuilder().getBuilderList();
    }
    private com.google.protobuf.RepeatedFieldBuilder<
            io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper, io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper.Builder, io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperOrBuilder>
    getItemsFieldBuilder() {
      if (itemsBuilder_ == null) {
        itemsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
                io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper, io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapper.Builder, io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperOrBuilder>(
                items_,
                ((bitField0_ & 0x00000002) != 0),
                getParentForChildren(),
                isClean());
        items_ = null;
      }
      return itemsBuilder_;
    }

    // @@protoc_insertion_point(builder_scope:metadata.v1.MetadataKeysetWrapperList)
  }

  // @@protoc_insertion_point(class_scope:metadata.v1.MetadataKeysetWrapperList)
  private static final io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList DEFAULT_INSTANCE;
  static {
    DEFAULT_INSTANCE = new io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList();
  }

  public static io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList getDefaultInstance() {
    return DEFAULT_INSTANCE;
  }

  private static final com.google.protobuf.Parser<MetadataKeysetWrapperList>
          PARSER = new com.google.protobuf.AbstractParser<MetadataKeysetWrapperList>() {
    @java.lang.Override
    public MetadataKeysetWrapperList parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
      Builder builder = newBuilder();
      try {
        builder.mergeFrom(input, extensionRegistry);
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(builder.buildPartial());
      } catch (com.google.protobuf.UninitializedMessageException e) {
        throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(e)
                .setUnfinishedMessage(builder.buildPartial());
      }
      return builder.buildPartial();
    }
  };

  public static com.google.protobuf.Parser<MetadataKeysetWrapperList> parser() {
    return PARSER;
  }

  @java.lang.Override
  public com.google.protobuf.Parser<MetadataKeysetWrapperList> getParserForType() {
    return PARSER;
  }

  @java.lang.Override
  public io.confluent.kafka.schemaregistry.storage.encoder.MetadataKeysetWrapperList getDefaultInstanceForType() {
    return DEFAULT_INSTANCE;
  }

}

