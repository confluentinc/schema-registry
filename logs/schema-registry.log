[2020-09-24 15:17:23,721] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	debug = false
	host.name = 192.168.0.116
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	kafkastore.zk.session.timeout.ms = 30000
	leader.eligibility = true
	listeners = [http://0.0.0.0:8081]
	master.eligibility = null
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2020-09-24 15:17:23,751] INFO Logging initialized @9393ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2020-09-24 15:17:23,758] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2020-09-24 15:17:23,831] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.ApplicationServer)
[2020-09-24 15:17:24,304] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-09-24 15:17:24,304] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-09-24 15:17:24,304] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-09-24 15:17:24,307] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-09-24 15:17:24,325] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-09-24 15:17:24,331] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-09-24 15:17:24,390] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-09-24 15:17:24,432] INFO Seeking to beginning for all partitions (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-09-24 15:17:24,432] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-09-24 15:17:24,433] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-09-24 15:17:24,535] INFO Wait to catch up until the offset at 9 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-09-24 15:17:24,561] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-09-24 15:17:24,613] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-b4b83f58-6c60-44e4-b7d7-13d08c2a3313', leaderIdentity=version=1,host=192.168.0.116,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2020-09-24 15:17:24,621] INFO Wait to catch up until the offset at 10 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-09-24 15:17:24,737] INFO jetty-9.4.30.v20200611; built: 2020-06-11T12:34:51.929Z; git: 271836e4c1f4612f12b7bb13ef5a92a927634b0d; jvm 1.8.0_265-b01 (org.eclipse.jetty.server.Server)
[2020-09-24 15:17:24,766] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2020-09-24 15:17:24,766] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2020-09-24 15:17:24,768] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session)
[2020-09-24 15:17:25,191] INFO HV000001: Hibernate Validator 6.1.2.Final (org.hibernate.validator.internal.util.Version)
[2020-09-24 15:17:25,397] INFO Started o.e.j.s.ServletContextHandler@63fbfaeb{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-09-24 15:17:25,407] INFO Started o.e.j.s.ServletContextHandler@38234a38{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-09-24 15:17:25,421] INFO Started NetworkTrafficServerConnector@69b0fd6f{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-09-24 15:17:25,421] INFO Started @11065ms (org.eclipse.jetty.server.Server)
[2020-09-24 15:17:25,421] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2020-09-24 15:17:48,474] INFO Registering new schema: subject granularactualbalance, version null, id null, type null (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2020-09-24 15:17:48,518] INFO 0:0:0:0:0:0:0:1 - - [24/Sep/2020:22:17:48 +0000] "POST /subjects/granularactualbalance/versions HTTP/1.1" 200 8  137 (io.confluent.rest-utils.requests)
[2020-09-24 15:17:55,995] INFO Registering new schema: subject granularactualbalance, version null, id null, type null (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2020-09-24 15:17:55,997] INFO Wait to catch up until the offset at 10 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-09-24 15:17:56,015] ERROR Unexpected exception during compatibility check (io.confluent.kafka.schemaregistry.avro.AvroSchema)
org.apache.avro.AvroTypeException: Non-null default value for null type: ""
	at org.apache.avro.io.parsing.ResolvingGrammarGenerator.encode(ResolvingGrammarGenerator.java:344)
	at org.apache.avro.io.parsing.ResolvingGrammarGenerator.encode(ResolvingGrammarGenerator.java:296)
	at org.apache.avro.io.parsing.ResolvingGrammarGenerator$1.encode(ResolvingGrammarGenerator.java:49)
	at org.apache.avro.util.internal.Accessor.encode(Accessor.java:109)
	at org.apache.avro.generic.GenericData.getDefaultValue(GenericData.java:1188)
	at org.apache.avro.Resolver$RecordAdjust.resolve(Resolver.java:551)
	at org.apache.avro.Resolver.resolve(Resolver.java:113)
	at org.apache.avro.Resolver.resolve(Resolver.java:62)
	at org.apache.avro.Resolver.resolve(Resolver.java:69)
	at org.apache.avro.io.parsing.ResolvingGrammarGenerator.generate(ResolvingGrammarGenerator.java:64)
	at org.apache.avro.ValidateMutualRead.canRead(ValidateMutualRead.java:60)
	at org.apache.avro.ValidateCanRead.validate(ValidateCanRead.java:38)
	at org.apache.avro.ValidateLatest.validate(ValidateLatest.java:49)
	at io.confluent.kafka.schemaregistry.avro.AvroSchema.isBackwardCompatible(AvroSchema.java:165)
	at io.confluent.kafka.schemaregistry.SchemaValidatorBuilder.lambda$canReadStrategy$0(SchemaValidatorBuilder.java:41)
	at io.confluent.kafka.schemaregistry.SchemaValidatorBuilder.lambda$validateLatest$3(SchemaValidatorBuilder.java:75)
	at io.confluent.kafka.schemaregistry.CompatibilityChecker.isCompatible(CompatibilityChecker.java:86)
	at io.confluent.kafka.schemaregistry.ParsedSchema.isCompatible(ParsedSchema.java:109)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.isCompatibleWithPrevious(KafkaSchemaRegistry.java:1326)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.register(KafkaSchemaRegistry.java:471)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.registerOrForward(KafkaSchemaRegistry.java:563)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.register(SubjectVersionsResource.java:266)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$VoidOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:159)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:469)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:391)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:80)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:253)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:232)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.ServletContainer.serviceImpl(ServletContainer.java:386)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:561)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:502)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:439)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1618)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:549)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1610)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1369)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:489)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1580)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1284)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:767)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:501)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:272)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:135)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
	at java.lang.Thread.run(Thread.java:748)
[2020-09-24 15:17:56,022] ERROR Request Failed with exception  (io.confluent.rest.exceptions.DebuggableExceptionMapper)
io.confluent.kafka.schemaregistry.rest.exceptions.RestIncompatibleSchemaException: Schema being registered is incompatible with an earlier schema for subject "granularactualbalance"
	at io.confluent.kafka.schemaregistry.rest.exceptions.Errors.incompatibleSchemaException(Errors.java:111)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.register(SubjectVersionsResource.java:282)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$VoidOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:159)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:469)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:391)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:80)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:253)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:232)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.ServletContainer.serviceImpl(ServletContainer.java:386)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:561)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:502)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:439)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1618)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:549)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1610)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1369)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:489)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1580)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1284)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:767)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:501)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:272)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:135)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
	at java.lang.Thread.run(Thread.java:748)
Caused by: io.confluent.kafka.schemaregistry.exceptions.IncompatibleSchemaException: New schema is incompatible with an earlier schema.
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.register(KafkaSchemaRegistry.java:514)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.registerOrForward(KafkaSchemaRegistry.java:563)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.register(SubjectVersionsResource.java:266)
	... 59 more
[2020-09-24 15:17:56,026] INFO 0:0:0:0:0:0:0:1 - - [24/Sep/2020:22:17:55 +0000] "POST /subjects/granularactualbalance/versions HTTP/1.1" 409 131  34 (io.confluent.rest-utils.requests)
[2020-09-24 15:19:49,200] ERROR Request Failed with exception  (io.confluent.rest.exceptions.DebuggableExceptionMapper)
javax.ws.rs.NotFoundException: HTTP 404 Not Found
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:250)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:232)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.ServletContainer.serviceImpl(ServletContainer.java:386)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:561)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:502)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:439)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1618)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:549)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1610)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1369)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:489)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1580)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1284)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:767)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:501)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:272)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
	at java.lang.Thread.run(Thread.java:748)
[2020-09-24 15:19:49,202] INFO 0:0:0:0:0:0:0:1 - - [24/Sep/2020:22:19:49 +0000] "POST /compatibility/subjects/granularactualbalance/versions HTTP/1.1" 404 49  3 (io.confluent.rest-utils.requests)
[2020-09-24 15:20:53,823] INFO Testing schema subject granularactualbalance compatibility between existing version latest and specified version null, id null, type null (io.confluent.kafka.schemaregistry.rest.resources.CompatibilityResource)
[2020-09-24 15:20:53,824] ERROR Unexpected exception during compatibility check (io.confluent.kafka.schemaregistry.avro.AvroSchema)
org.apache.avro.AvroTypeException: Non-null default value for null type: ""
	at org.apache.avro.io.parsing.ResolvingGrammarGenerator.encode(ResolvingGrammarGenerator.java:344)
	at org.apache.avro.io.parsing.ResolvingGrammarGenerator.encode(ResolvingGrammarGenerator.java:296)
	at org.apache.avro.io.parsing.ResolvingGrammarGenerator$1.encode(ResolvingGrammarGenerator.java:49)
	at org.apache.avro.util.internal.Accessor.encode(Accessor.java:109)
	at org.apache.avro.generic.GenericData.getDefaultValue(GenericData.java:1188)
	at org.apache.avro.Resolver$RecordAdjust.resolve(Resolver.java:551)
	at org.apache.avro.Resolver.resolve(Resolver.java:113)
	at org.apache.avro.Resolver.resolve(Resolver.java:62)
	at org.apache.avro.Resolver.resolve(Resolver.java:69)
	at org.apache.avro.io.parsing.ResolvingGrammarGenerator.generate(ResolvingGrammarGenerator.java:64)
	at org.apache.avro.ValidateMutualRead.canRead(ValidateMutualRead.java:60)
	at org.apache.avro.ValidateCanRead.validate(ValidateCanRead.java:38)
	at org.apache.avro.ValidateLatest.validate(ValidateLatest.java:49)
	at io.confluent.kafka.schemaregistry.avro.AvroSchema.isBackwardCompatible(AvroSchema.java:165)
	at io.confluent.kafka.schemaregistry.SchemaValidatorBuilder.lambda$canReadStrategy$0(SchemaValidatorBuilder.java:41)
	at io.confluent.kafka.schemaregistry.SchemaValidatorBuilder.lambda$validateLatest$3(SchemaValidatorBuilder.java:75)
	at io.confluent.kafka.schemaregistry.CompatibilityChecker.isCompatible(CompatibilityChecker.java:86)
	at io.confluent.kafka.schemaregistry.ParsedSchema.isCompatible(ParsedSchema.java:109)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.isCompatibleWithPrevious(KafkaSchemaRegistry.java:1326)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.isCompatible(KafkaSchemaRegistry.java:1317)
	at io.confluent.kafka.schemaregistry.rest.resources.CompatibilityResource.testCompatibilityBySubjectName(CompatibilityResource.java:129)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$VoidOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:159)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:469)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:391)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:80)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:253)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:232)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.ServletContainer.serviceImpl(ServletContainer.java:386)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:561)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:502)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:439)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1618)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:549)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1610)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1369)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:489)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1580)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1284)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:767)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:501)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:272)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
	at java.lang.Thread.run(Thread.java:748)
[2020-09-24 15:20:53,828] INFO 0:0:0:0:0:0:0:1 - - [24/Sep/2020:22:20:53 +0000] "POST /compatibility/subjects/granularactualbalance/versions/latest?verbose=true HTTP/1.1" 200 130  12 (io.confluent.rest-utils.requests)
[2020-09-24 15:42:21,098] WARN  (org.eclipse.jetty.server.AbstractConnector)
java.io.IOException: Thread signal failed
	at sun.nio.ch.NativeThread.signal(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.implCloseSelectableChannel(ServerSocketChannelImpl.java:289)
	at java.nio.channels.spi.AbstractSelectableChannel.implCloseChannel(AbstractSelectableChannel.java:241)
	at java.nio.channels.spi.AbstractInterruptibleChannel.close(AbstractInterruptibleChannel.java:115)
	at org.eclipse.jetty.server.ServerConnector.close(ServerConnector.java:371)
	at org.eclipse.jetty.server.AbstractNetworkConnector.shutdown(AbstractNetworkConnector.java:104)
	at org.eclipse.jetty.server.Server.doStop(Server.java:429)
	at io.confluent.rest.ApplicationServer.doStop(ApplicationServer.java:217)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:93)
	at org.eclipse.jetty.util.thread.ShutdownThread.run(ShutdownThread.java:128)
[2020-09-24 15:42:21,102] INFO Stopped NetworkTrafficServerConnector@69b0fd6f{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-09-24 15:42:21,103] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2020-09-24 15:42:21,104] INFO Stopped o.e.j.s.ServletContextHandler@38234a38{/ws,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-09-24 15:42:21,109] INFO Stopped o.e.j.s.ServletContextHandler@63fbfaeb{/,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-09-24 15:42:21,110] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-09-24 15:42:21,110] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-09-24 15:42:21,111] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-09-24 15:42:21,111] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-09-24 15:42:21,112] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-09-24 15:42:21,113] ERROR Unexpected exception in schema registry group processing thread (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
org.apache.kafka.common.errors.WakeupException
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.maybeTriggerWakeup(ConsumerNetworkClient.java:514)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:278)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:227)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator.poll(SchemaRegistryCoordinator.java:124)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector$1.run(KafkaGroupLeaderElector.java:202)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-10-01 16:05:29,303] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	debug = false
	host.name = 192.168.0.116
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	kafkastore.zk.session.timeout.ms = 30000
	leader.eligibility = true
	listeners = [http://0.0.0.0:8081]
	master.eligibility = null
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2020-10-01 16:05:29,340] INFO Logging initialized @6689ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2020-10-01 16:05:29,348] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2020-10-01 16:05:29,422] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.ApplicationServer)
[2020-10-01 16:05:30,029] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-10-01 16:05:30,029] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-10-01 16:05:30,029] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-10-01 16:05:30,033] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-10-01 16:05:30,047] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-10-01 16:05:30,052] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-10-01 16:05:30,066] ERROR The retention policy of the schema topic _schemas is incorrect. You must configure the topic to 'compact' cleanup policy to avoid Kafka deleting your schemas after a week. Refer to Kafka documentation for more details on cleanup policies (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-10-01 16:05:30,069] ERROR Error starting the schema registry (io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication)
io.confluent.kafka.schemaregistry.exceptions.SchemaRegistryInitializationException: Error initializing kafka store while initializing schema registry
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.init(KafkaSchemaRegistry.java:297)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.initSchemaRegistry(SchemaRegistryRestApplication.java:73)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.configureBaseApplication(SchemaRegistryRestApplication.java:88)
	at io.confluent.rest.Application.configureHandler(Application.java:254)
	at io.confluent.rest.ApplicationServer.doStart(ApplicationServer.java:227)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:72)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain.main(SchemaRegistryMain.java:43)
Caused by: io.confluent.kafka.schemaregistry.storage.exceptions.StoreInitializationException: The retention policy of the schema topic _schemas is incorrect. Expected cleanup.policy to be 'compact' but it is delete
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.verifySchemaTopic(KafkaStore.java:270)
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.createOrVerifySchemaTopic(KafkaStore.java:171)
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.init(KafkaStore.java:118)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.init(KafkaSchemaRegistry.java:295)
	... 6 more
[2020-10-01 16:10:31,288] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	debug = false
	host.name = 192.168.0.116
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	kafkastore.zk.session.timeout.ms = 30000
	leader.eligibility = true
	listeners = [http://0.0.0.0:8081]
	master.eligibility = null
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2020-10-01 16:10:31,326] INFO Logging initialized @10092ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2020-10-01 16:10:31,334] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2020-10-01 16:10:31,410] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.ApplicationServer)
[2020-10-01 16:10:32,022] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-10-01 16:10:32,022] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-10-01 16:10:32,022] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-10-01 16:10:32,026] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-10-01 16:10:32,039] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-10-01 16:10:32,044] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-10-01 16:10:32,052] ERROR The retention policy of the schema topic _schemas is incorrect. You must configure the topic to 'compact' cleanup policy to avoid Kafka deleting your schemas after a week. Refer to Kafka documentation for more details on cleanup policies (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-10-01 16:10:32,056] ERROR Error starting the schema registry (io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication)
io.confluent.kafka.schemaregistry.exceptions.SchemaRegistryInitializationException: Error initializing kafka store while initializing schema registry
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.init(KafkaSchemaRegistry.java:297)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.initSchemaRegistry(SchemaRegistryRestApplication.java:73)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.configureBaseApplication(SchemaRegistryRestApplication.java:88)
	at io.confluent.rest.Application.configureHandler(Application.java:254)
	at io.confluent.rest.ApplicationServer.doStart(ApplicationServer.java:227)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:72)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain.main(SchemaRegistryMain.java:43)
Caused by: io.confluent.kafka.schemaregistry.storage.exceptions.StoreInitializationException: The retention policy of the schema topic _schemas is incorrect. Expected cleanup.policy to be 'compact' but it is delete
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.verifySchemaTopic(KafkaStore.java:270)
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.createOrVerifySchemaTopic(KafkaStore.java:171)
	at io.confluent.kafka.schemaregistry.storage.KafkaStore.init(KafkaStore.java:118)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.init(KafkaSchemaRegistry.java:295)
	... 6 more
[2020-10-01 16:45:27,610] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	debug = false
	host.name = 192.168.0.116
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	kafkastore.zk.session.timeout.ms = 30000
	leader.eligibility = true
	listeners = [http://0.0.0.0:8081]
	master.eligibility = null
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2020-10-01 16:45:27,657] INFO Logging initialized @578ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2020-10-01 16:45:27,668] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2020-10-01 16:45:27,749] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.ApplicationServer)
[2020-10-01 16:45:28,361] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-10-01 16:45:28,361] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-10-01 16:45:28,361] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-10-01 16:45:28,364] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-10-01 16:45:28,377] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-10-01 16:45:28,382] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-10-01 16:45:28,448] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-10-01 16:45:28,496] INFO Seeking to beginning for all partitions (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-10-01 16:45:28,497] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-10-01 16:45:28,498] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-10-01 16:45:28,568] INFO Wait to catch up until the offset at 2 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-10-01 16:45:28,586] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-10-01 16:45:28,622] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-d98e0014-2747-458e-a666-7326bab77471', leaderIdentity=version=1,host=192.168.0.116,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2020-10-01 16:45:28,630] INFO Wait to catch up until the offset at 3 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-10-01 16:45:28,788] INFO jetty-9.4.30.v20200611; built: 2020-06-11T12:34:51.929Z; git: 271836e4c1f4612f12b7bb13ef5a92a927634b0d; jvm 1.8.0_265-b01 (org.eclipse.jetty.server.Server)
[2020-10-01 16:45:28,818] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2020-10-01 16:45:28,818] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2020-10-01 16:45:28,820] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session)
[2020-10-01 16:45:29,322] INFO HV000001: Hibernate Validator 6.1.2.Final (org.hibernate.validator.internal.util.Version)
[2020-10-01 16:45:29,569] INFO Started o.e.j.s.ServletContextHandler@5bf0fe62{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-10-01 16:45:29,581] INFO Started o.e.j.s.ServletContextHandler@1c33c17b{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-10-01 16:45:29,594] INFO Started NetworkTrafficServerConnector@4a87761d{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-10-01 16:45:29,594] INFO Started @2517ms (org.eclipse.jetty.server.Server)
[2020-10-01 16:45:29,594] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2020-10-01 16:45:43,240] INFO Registering new schema: subject Kafka-value, version null, id null, type null (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2020-10-01 16:45:43,264] INFO Wait to catch up until the offset at 3 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-10-01 16:45:43,275] INFO Wait to catch up until the offset at 4 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-10-01 16:45:43,305] INFO 0:0:0:0:0:0:0:1 - - [01/Oct/2020:23:45:43 +0000] "POST /subjects/Kafka-value/versions HTTP/1.1" 200 8  175 (io.confluent.rest-utils.requests)
[2020-10-01 16:55:08,959] WARN  (org.eclipse.jetty.server.AbstractConnector)
java.io.IOException: Thread signal failed
	at sun.nio.ch.NativeThread.signal(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.implCloseSelectableChannel(ServerSocketChannelImpl.java:289)
	at java.nio.channels.spi.AbstractSelectableChannel.implCloseChannel(AbstractSelectableChannel.java:241)
	at java.nio.channels.spi.AbstractInterruptibleChannel.close(AbstractInterruptibleChannel.java:115)
	at org.eclipse.jetty.server.ServerConnector.close(ServerConnector.java:371)
	at org.eclipse.jetty.server.AbstractNetworkConnector.shutdown(AbstractNetworkConnector.java:104)
	at org.eclipse.jetty.server.Server.doStop(Server.java:429)
	at io.confluent.rest.ApplicationServer.doStop(ApplicationServer.java:217)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:93)
	at org.eclipse.jetty.util.thread.ShutdownThread.run(ShutdownThread.java:128)
[2020-10-01 16:55:08,964] INFO Stopped NetworkTrafficServerConnector@4a87761d{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-10-01 16:55:08,965] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2020-10-01 16:55:08,966] INFO Stopped o.e.j.s.ServletContextHandler@1c33c17b{/ws,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-10-01 16:55:08,972] INFO Stopped o.e.j.s.ServletContextHandler@5bf0fe62{/,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-10-01 16:55:08,973] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-10-01 16:55:08,974] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-10-01 16:55:08,974] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-10-01 16:55:08,974] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-10-01 16:55:08,976] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-10-01 16:55:08,977] ERROR Unexpected exception in schema registry group processing thread (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
org.apache.kafka.common.errors.WakeupException
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.maybeTriggerWakeup(ConsumerNetworkClient.java:514)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:278)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:227)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator.poll(SchemaRegistryCoordinator.java:124)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector$1.run(KafkaGroupLeaderElector.java:202)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-11-10 16:19:59,659] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	debug = false
	host.name = 192.168.0.105
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	kafkastore.zk.session.timeout.ms = 30000
	leader.eligibility = true
	listeners = [http://0.0.0.0:8081]
	master.eligibility = null
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2020-11-10 16:19:59,707] INFO Logging initialized @4349ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2020-11-10 16:19:59,715] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2020-11-10 16:19:59,787] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.ApplicationServer)
[2020-11-10 16:20:00,370] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 16:20:00,370] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 16:20:00,370] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 16:20:00,374] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 16:20:00,388] INFO Creating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 16:20:00,389] WARN Creating the schema topic _schemas using a replication factor of 1, which is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 16:20:00,465] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 16:20:00,508] INFO Seeking to beginning for all partitions (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 16:20:00,509] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 16:20:00,510] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 16:20:00,593] INFO Wait to catch up until the offset at 0 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 16:20:00,635] INFO Reached offset at 0 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 16:20:00,636] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 16:20:01,004] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-8bdd6edc-e6fe-4bef-9fe2-bf9be000b2ca', leaderIdentity=version=1,host=192.168.0.105,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2020-11-10 16:20:01,012] INFO Wait to catch up until the offset at 1 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 16:20:01,013] INFO Reached offset at 1 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 16:20:01,146] INFO jetty-9.4.30.v20200611; built: 2020-06-11T12:34:51.929Z; git: 271836e4c1f4612f12b7bb13ef5a92a927634b0d; jvm 1.8.0_265-b01 (org.eclipse.jetty.server.Server)
[2020-11-10 16:20:01,175] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2020-11-10 16:20:01,176] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2020-11-10 16:20:01,177] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session)
[2020-11-10 16:20:01,629] INFO HV000001: Hibernate Validator 6.1.2.Final (org.hibernate.validator.internal.util.Version)
[2020-11-10 16:20:01,849] INFO Started o.e.j.s.ServletContextHandler@8c3619e{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 16:20:01,859] INFO Started o.e.j.s.ServletContextHandler@3ad2e17{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 16:20:01,872] INFO Started NetworkTrafficServerConnector@43738a82{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-11-10 16:20:01,872] INFO Started @6516ms (org.eclipse.jetty.server.Server)
[2020-11-10 16:20:01,873] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2020-11-10 16:20:21,990] INFO Rebalance started (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2020-11-10 16:20:21,993] ERROR Found duplicate URLs for schema registry group members. This indicates a misconfiguration and is common when executing in containers. Use the host.name configuration to set each instance's advertised host name to a value that is routable from all other schema registry instances. (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2020-11-10 16:20:21,997] INFO Finished rebalance with leader election result: Assignment{version=1, error=1, leader='sr-1-63b45004-6039-4007-8aec-470be2a53520', leaderIdentity=version=1,host=192.168.0.105,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2020-11-10 16:20:21,998] ERROR Unexpected exception in schema registry group processing thread (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
java.lang.IllegalStateException: The schema registry group contained multiple members advertising the same URL. Verify that each instance has a unique, routable listener by setting the 'listeners' configuration. This error may happen if executing in containers where the default hostname is 'localhost'.
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector.onAssigned(KafkaGroupLeaderElector.java:248)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator.onJoinComplete(SchemaRegistryCoordinator.java:149)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.joinGroupIfNeeded(AbstractCoordinator.java:451)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureActiveGroup(AbstractCoordinator.java:367)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureActiveGroup(AbstractCoordinator.java:347)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator.poll(SchemaRegistryCoordinator.java:113)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector$1.run(KafkaGroupLeaderElector.java:202)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-11-10 16:20:54,495] INFO 127.0.0.1 - - [11/Nov/2020:00:20:54 +0000] "GET / HTTP/1.1" 200 2  116 (io.confluent.rest-utils.requests)
[2020-11-10 16:21:16,243] INFO 127.0.0.1 - - [11/Nov/2020:00:21:16 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:21:38,918] INFO 127.0.0.1 - - [11/Nov/2020:00:21:38 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:21:57,628] INFO 127.0.0.1 - - [11/Nov/2020:00:21:57 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:22:17,054] INFO 127.0.0.1 - - [11/Nov/2020:00:22:17 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 16:22:22,641] ERROR Request Failed with exception  (io.confluent.rest.exceptions.DebuggableExceptionMapper)
io.confluent.rest.exceptions.RestNotFoundException: Subject 'default_ksql_processing_log-value' not found.
	at io.confluent.kafka.schemaregistry.rest.exceptions.Errors.subjectNotFoundException(Errors.java:69)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.listVersions(SubjectVersionsResource.java:197)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$TypeOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:219)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:469)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:391)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:80)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:253)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:232)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.ServletContainer.serviceImpl(ServletContainer.java:386)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:561)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:502)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:439)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1618)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:549)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1610)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1369)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:489)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1580)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1284)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:767)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:501)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:272)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:135)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
	at java.lang.Thread.run(Thread.java:748)
[2020-11-10 16:22:22,644] INFO 127.0.0.1 - - [11/Nov/2020:00:22:22 +0000] "GET /subjects/default_ksql_processing_log-value/versions HTTP/1.1" 404 87  32 (io.confluent.rest-utils.requests)
[2020-11-10 16:22:34,352] INFO 127.0.0.1 - - [11/Nov/2020:00:22:34 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:22:54,597] INFO 127.0.0.1 - - [11/Nov/2020:00:22:54 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:23:13,721] INFO 127.0.0.1 - - [11/Nov/2020:00:23:13 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:23:31,430] INFO 127.0.0.1 - - [11/Nov/2020:00:23:31 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:23:54,344] INFO 127.0.0.1 - - [11/Nov/2020:00:23:54 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 16:24:14,473] INFO 127.0.0.1 - - [11/Nov/2020:00:24:14 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 16:24:31,544] INFO 127.0.0.1 - - [11/Nov/2020:00:24:31 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:24:52,954] INFO 127.0.0.1 - - [11/Nov/2020:00:24:52 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:25:09,712] INFO 127.0.0.1 - - [11/Nov/2020:00:25:09 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:25:27,227] INFO 127.0.0.1 - - [11/Nov/2020:00:25:27 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 16:25:48,991] INFO 127.0.0.1 - - [11/Nov/2020:00:25:48 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:26:05,568] INFO 127.0.0.1 - - [11/Nov/2020:00:26:05 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:26:22,178] INFO 127.0.0.1 - - [11/Nov/2020:00:26:22 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 16:26:46,060] INFO 127.0.0.1 - - [11/Nov/2020:00:26:46 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:27:02,338] INFO 127.0.0.1 - - [11/Nov/2020:00:27:02 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:27:19,432] INFO 127.0.0.1 - - [11/Nov/2020:00:27:19 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:27:37,495] INFO 127.0.0.1 - - [11/Nov/2020:00:27:37 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:28:00,377] INFO 127.0.0.1 - - [11/Nov/2020:00:28:00 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:28:23,479] INFO 127.0.0.1 - - [11/Nov/2020:00:28:23 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:28:44,265] INFO 127.0.0.1 - - [11/Nov/2020:00:28:44 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:29:08,233] INFO 127.0.0.1 - - [11/Nov/2020:00:29:08 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:29:29,890] INFO 127.0.0.1 - - [11/Nov/2020:00:29:29 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:29:47,653] INFO 127.0.0.1 - - [11/Nov/2020:00:29:47 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:30:11,510] INFO 127.0.0.1 - - [11/Nov/2020:00:30:11 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:30:34,110] INFO 127.0.0.1 - - [11/Nov/2020:00:30:34 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:30:54,453] INFO 127.0.0.1 - - [11/Nov/2020:00:30:54 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 16:31:12,954] INFO 127.0.0.1 - - [11/Nov/2020:00:31:12 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:31:34,132] INFO 127.0.0.1 - - [11/Nov/2020:00:31:34 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:31:57,004] INFO 127.0.0.1 - - [11/Nov/2020:00:31:57 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:32:16,855] INFO 127.0.0.1 - - [11/Nov/2020:00:32:16 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:32:39,006] INFO 127.0.0.1 - - [11/Nov/2020:00:32:39 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:32:59,901] INFO 127.0.0.1 - - [11/Nov/2020:00:32:59 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:33:18,572] INFO 127.0.0.1 - - [11/Nov/2020:00:33:18 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:33:37,343] INFO 127.0.0.1 - - [11/Nov/2020:00:33:37 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:33:57,132] INFO 127.0.0.1 - - [11/Nov/2020:00:33:57 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:34:15,697] INFO 127.0.0.1 - - [11/Nov/2020:00:34:15 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:34:32,142] INFO 127.0.0.1 - - [11/Nov/2020:00:34:32 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:34:48,750] INFO 127.0.0.1 - - [11/Nov/2020:00:34:48 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:35:10,635] INFO 127.0.0.1 - - [11/Nov/2020:00:35:10 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:35:33,891] INFO 127.0.0.1 - - [11/Nov/2020:00:35:33 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:35:55,507] INFO 127.0.0.1 - - [11/Nov/2020:00:35:55 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:36:18,267] INFO 127.0.0.1 - - [11/Nov/2020:00:36:18 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:36:35,577] INFO 127.0.0.1 - - [11/Nov/2020:00:36:35 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:36:54,112] INFO 127.0.0.1 - - [11/Nov/2020:00:36:54 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:37:17,928] INFO 127.0.0.1 - - [11/Nov/2020:00:37:17 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:37:35,252] INFO 127.0.0.1 - - [11/Nov/2020:00:37:35 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:37:56,762] INFO 127.0.0.1 - - [11/Nov/2020:00:37:56 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:38:17,980] INFO 127.0.0.1 - - [11/Nov/2020:00:38:17 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:38:38,370] INFO 127.0.0.1 - - [11/Nov/2020:00:38:38 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:38:55,461] INFO 127.0.0.1 - - [11/Nov/2020:00:38:55 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:39:15,236] INFO 127.0.0.1 - - [11/Nov/2020:00:39:15 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:39:37,587] INFO 127.0.0.1 - - [11/Nov/2020:00:39:37 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:39:59,159] INFO 127.0.0.1 - - [11/Nov/2020:00:39:59 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:40:22,497] INFO 127.0.0.1 - - [11/Nov/2020:00:40:22 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:40:46,156] INFO 127.0.0.1 - - [11/Nov/2020:00:40:46 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:41:07,878] INFO 127.0.0.1 - - [11/Nov/2020:00:41:07 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:41:29,119] INFO 127.0.0.1 - - [11/Nov/2020:00:41:29 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:41:50,375] INFO 127.0.0.1 - - [11/Nov/2020:00:41:50 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:42:09,923] INFO 127.0.0.1 - - [11/Nov/2020:00:42:09 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:42:29,103] INFO 127.0.0.1 - - [11/Nov/2020:00:42:29 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:42:52,689] INFO 127.0.0.1 - - [11/Nov/2020:00:42:52 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:43:12,241] INFO 127.0.0.1 - - [11/Nov/2020:00:43:12 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:43:29,334] INFO 127.0.0.1 - - [11/Nov/2020:00:43:29 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:43:52,666] INFO 127.0.0.1 - - [11/Nov/2020:00:43:52 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:44:16,246] INFO 127.0.0.1 - - [11/Nov/2020:00:44:16 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:44:35,262] INFO 127.0.0.1 - - [11/Nov/2020:00:44:35 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:44:56,141] INFO 127.0.0.1 - - [11/Nov/2020:00:44:56 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:45:13,413] INFO 127.0.0.1 - - [11/Nov/2020:00:45:13 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:45:32,034] INFO 127.0.0.1 - - [11/Nov/2020:00:45:32 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:45:51,812] INFO 127.0.0.1 - - [11/Nov/2020:00:45:51 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:46:15,010] INFO 127.0.0.1 - - [11/Nov/2020:00:46:15 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:46:38,094] INFO 127.0.0.1 - - [11/Nov/2020:00:46:38 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:46:55,625] INFO 127.0.0.1 - - [11/Nov/2020:00:46:55 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:47:18,652] INFO 127.0.0.1 - - [11/Nov/2020:00:47:18 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:47:41,007] INFO 127.0.0.1 - - [11/Nov/2020:00:47:41 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:48:02,190] INFO 127.0.0.1 - - [11/Nov/2020:00:48:02 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:48:26,043] INFO 127.0.0.1 - - [11/Nov/2020:00:48:26 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:48:43,606] INFO 127.0.0.1 - - [11/Nov/2020:00:48:43 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:49:00,974] INFO 127.0.0.1 - - [11/Nov/2020:00:49:00 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:49:19,203] INFO 127.0.0.1 - - [11/Nov/2020:00:49:19 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:49:40,260] INFO 127.0.0.1 - - [11/Nov/2020:00:49:40 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:50:00,683] INFO 127.0.0.1 - - [11/Nov/2020:00:50:00 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:50:24,673] INFO 127.0.0.1 - - [11/Nov/2020:00:50:24 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:50:46,347] INFO 127.0.0.1 - - [11/Nov/2020:00:50:46 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:51:05,619] INFO 127.0.0.1 - - [11/Nov/2020:00:51:05 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:51:25,244] INFO 127.0.0.1 - - [11/Nov/2020:00:51:25 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:51:47,914] INFO 127.0.0.1 - - [11/Nov/2020:00:51:47 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:52:07,815] INFO 127.0.0.1 - - [11/Nov/2020:00:52:07 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:52:28,488] INFO 127.0.0.1 - - [11/Nov/2020:00:52:28 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:52:45,685] INFO 127.0.0.1 - - [11/Nov/2020:00:52:45 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:53:05,707] INFO 127.0.0.1 - - [11/Nov/2020:00:53:05 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:53:13,580] ERROR Request Failed with exception  (io.confluent.rest.exceptions.DebuggableExceptionMapper)
io.confluent.rest.exceptions.RestNotFoundException: Subject 'default_ksql_processing_log-value' not found.
	at io.confluent.kafka.schemaregistry.rest.exceptions.Errors.subjectNotFoundException(Errors.java:69)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.listVersions(SubjectVersionsResource.java:197)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$TypeOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:219)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:469)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:391)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:80)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:253)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:232)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.ServletContainer.serviceImpl(ServletContainer.java:386)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:561)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:502)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:439)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1618)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:549)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1610)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1369)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:489)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1580)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1284)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:767)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:501)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:272)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
	at java.lang.Thread.run(Thread.java:748)
[2020-11-10 16:53:13,582] INFO 127.0.0.1 - - [11/Nov/2020:00:53:13 +0000] "GET /subjects/default_ksql_processing_log-value/versions HTTP/1.1" 404 87  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:53:29,439] INFO 127.0.0.1 - - [11/Nov/2020:00:53:29 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:53:40,113] INFO Stopped NetworkTrafficServerConnector@43738a82{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-11-10 16:53:40,113] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2020-11-10 16:53:40,114] INFO Stopped o.e.j.s.ServletContextHandler@3ad2e17{/ws,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 16:53:40,119] INFO Stopped o.e.j.s.ServletContextHandler@8c3619e{/,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 16:53:40,120] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 16:53:40,120] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 16:53:40,121] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 16:53:40,121] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 16:53:40,122] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 16:53:40,123] INFO Kafka store producer shut down (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 16:53:40,123] INFO Kafka store shut down complete (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 16:56:00,274] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	debug = false
	host.name = 192.168.0.105
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	kafkastore.zk.session.timeout.ms = 30000
	leader.eligibility = true
	listeners = [http://0.0.0.0:8081]
	master.eligibility = null
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2020-11-10 16:56:00,320] INFO Logging initialized @421ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2020-11-10 16:56:00,327] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2020-11-10 16:56:00,397] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.ApplicationServer)
[2020-11-10 16:56:00,875] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 16:56:00,875] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 16:56:00,875] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 16:56:00,879] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 16:56:00,891] INFO Creating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 16:56:00,892] WARN Creating the schema topic _schemas using a replication factor of 1, which is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 16:56:00,957] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 16:56:01,003] INFO Seeking to beginning for all partitions (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 16:56:01,003] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 16:56:01,004] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 16:56:01,110] INFO Wait to catch up until the offset at 0 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 16:56:01,141] INFO Reached offset at 0 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 16:56:01,142] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 16:56:01,516] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-a96b86d2-663c-45bd-adfe-ca3414008cd5', leaderIdentity=version=1,host=192.168.0.105,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2020-11-10 16:56:01,525] INFO Wait to catch up until the offset at 1 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 16:56:01,525] INFO Reached offset at 1 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 16:56:01,657] INFO jetty-9.4.30.v20200611; built: 2020-06-11T12:34:51.929Z; git: 271836e4c1f4612f12b7bb13ef5a92a927634b0d; jvm 1.8.0_265-b01 (org.eclipse.jetty.server.Server)
[2020-11-10 16:56:01,683] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2020-11-10 16:56:01,683] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2020-11-10 16:56:01,685] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session)
[2020-11-10 16:56:02,103] INFO HV000001: Hibernate Validator 6.1.2.Final (org.hibernate.validator.internal.util.Version)
[2020-11-10 16:56:02,304] INFO Started o.e.j.s.ServletContextHandler@8c3619e{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 16:56:02,315] INFO Started o.e.j.s.ServletContextHandler@3ad2e17{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 16:56:02,327] INFO Started NetworkTrafficServerConnector@43738a82{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-11-10 16:56:02,327] INFO Started @2430ms (org.eclipse.jetty.server.Server)
[2020-11-10 16:56:02,328] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2020-11-10 16:56:58,316] INFO 127.0.0.1 - - [11/Nov/2020:00:56:58 +0000] "GET / HTTP/1.1" 200 2  84 (io.confluent.rest-utils.requests)
[2020-11-10 16:57:16,030] INFO 127.0.0.1 - - [11/Nov/2020:00:57:16 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:57:33,431] INFO 127.0.0.1 - - [11/Nov/2020:00:57:33 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 16:57:50,938] INFO 127.0.0.1 - - [11/Nov/2020:00:57:50 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:58:10,952] INFO 127.0.0.1 - - [11/Nov/2020:00:58:10 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:58:32,394] INFO 127.0.0.1 - - [11/Nov/2020:00:58:32 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:58:54,862] INFO 127.0.0.1 - - [11/Nov/2020:00:58:54 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:59:12,142] INFO 127.0.0.1 - - [11/Nov/2020:00:59:12 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 16:59:29,429] INFO Stopped NetworkTrafficServerConnector@43738a82{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-11-10 16:59:29,430] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2020-11-10 16:59:29,431] INFO Stopped o.e.j.s.ServletContextHandler@3ad2e17{/ws,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 16:59:29,436] INFO Stopped o.e.j.s.ServletContextHandler@8c3619e{/,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 16:59:29,444] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 16:59:29,445] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 16:59:29,445] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 16:59:29,445] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 16:59:29,447] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 16:59:29,448] INFO Kafka store producer shut down (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 16:59:29,448] INFO Kafka store shut down complete (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 16:59:29,449] ERROR Unexpected exception in schema registry group processing thread (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
org.apache.kafka.common.errors.WakeupException
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.maybeTriggerWakeup(ConsumerNetworkClient.java:514)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:278)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:227)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator.poll(SchemaRegistryCoordinator.java:124)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector$1.run(KafkaGroupLeaderElector.java:202)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-11-10 17:01:24,611] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	debug = false
	host.name = 192.168.0.105
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	kafkastore.zk.session.timeout.ms = 30000
	leader.eligibility = true
	listeners = [http://0.0.0.0:8081]
	master.eligibility = null
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2020-11-10 17:01:24,655] INFO Logging initialized @406ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2020-11-10 17:01:24,663] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2020-11-10 17:01:24,733] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.ApplicationServer)
[2020-11-10 17:01:25,195] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 17:01:25,195] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 17:01:25,195] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 17:01:25,199] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 17:01:25,212] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 17:01:25,218] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 17:01:25,269] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 17:01:25,310] INFO Seeking to beginning for all partitions (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 17:01:25,311] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 17:01:25,313] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 17:01:25,377] INFO Wait to catch up until the offset at 2 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 17:01:25,393] INFO Reached offset at 2 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 17:01:25,395] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 17:01:25,433] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-d21d933a-2e13-41f6-b8ad-3bff15600c51', leaderIdentity=version=1,host=192.168.0.105,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2020-11-10 17:01:25,440] INFO Wait to catch up until the offset at 3 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 17:01:25,441] INFO Reached offset at 3 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 17:01:25,570] INFO jetty-9.4.30.v20200611; built: 2020-06-11T12:34:51.929Z; git: 271836e4c1f4612f12b7bb13ef5a92a927634b0d; jvm 1.8.0_265-b01 (org.eclipse.jetty.server.Server)
[2020-11-10 17:01:25,598] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2020-11-10 17:01:25,598] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2020-11-10 17:01:25,599] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session)
[2020-11-10 17:01:26,012] INFO HV000001: Hibernate Validator 6.1.2.Final (org.hibernate.validator.internal.util.Version)
[2020-11-10 17:01:26,215] INFO Started o.e.j.s.ServletContextHandler@7f0d96f2{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 17:01:26,225] INFO Started o.e.j.s.ServletContextHandler@2c4d1ac{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 17:01:26,237] INFO Started NetworkTrafficServerConnector@43738a82{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-11-10 17:01:26,238] INFO Started @1990ms (org.eclipse.jetty.server.Server)
[2020-11-10 17:01:26,238] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2020-11-10 17:01:33,220] INFO 127.0.0.1 - - [11/Nov/2020:01:01:33 +0000] "GET / HTTP/1.1" 200 2  87 (io.confluent.rest-utils.requests)
[2020-11-10 17:01:56,496] INFO 127.0.0.1 - - [11/Nov/2020:01:01:56 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 17:02:18,192] INFO 127.0.0.1 - - [11/Nov/2020:01:02:18 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 17:02:36,405] INFO 127.0.0.1 - - [11/Nov/2020:01:02:36 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 17:03:00,182] INFO 127.0.0.1 - - [11/Nov/2020:01:03:00 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:03:23,602] INFO 127.0.0.1 - - [11/Nov/2020:01:03:23 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:03:42,618] INFO 127.0.0.1 - - [11/Nov/2020:01:03:42 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 17:04:01,421] INFO 127.0.0.1 - - [11/Nov/2020:01:04:01 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:04:17,521] INFO 127.0.0.1 - - [11/Nov/2020:01:04:17 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:04:35,659] INFO 127.0.0.1 - - [11/Nov/2020:01:04:35 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:04:52,872] INFO 127.0.0.1 - - [11/Nov/2020:01:04:52 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 17:05:12,072] INFO 127.0.0.1 - - [11/Nov/2020:01:05:12 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 17:05:34,266] INFO 127.0.0.1 - - [11/Nov/2020:01:05:34 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:05:55,656] INFO 127.0.0.1 - - [11/Nov/2020:01:05:55 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:06:12,543] INFO 127.0.0.1 - - [11/Nov/2020:01:06:12 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:06:28,945] INFO 127.0.0.1 - - [11/Nov/2020:01:06:28 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:06:45,294] ERROR Request Failed with exception  (io.confluent.rest.exceptions.DebuggableExceptionMapper)
io.confluent.rest.exceptions.RestNotFoundException: Subject 'mytopic-value' not found.
	at io.confluent.kafka.schemaregistry.rest.exceptions.Errors.subjectNotFoundException(Errors.java:69)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.listVersions(SubjectVersionsResource.java:197)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$TypeOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:219)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:469)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:391)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:80)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:253)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:232)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.ServletContainer.serviceImpl(ServletContainer.java:386)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:561)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:502)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:439)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1618)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:549)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1610)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1369)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:489)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1580)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1284)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:767)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:501)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:272)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
	at java.lang.Thread.run(Thread.java:748)
[2020-11-10 17:06:45,298] INFO 127.0.0.1 - - [11/Nov/2020:01:06:45 +0000] "GET /subjects/mytopic-value/versions HTTP/1.1" 404 67  32 (io.confluent.rest-utils.requests)
[2020-11-10 17:06:47,225] INFO 127.0.0.1 - - [11/Nov/2020:01:06:47 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 17:07:06,298] INFO 127.0.0.1 - - [11/Nov/2020:01:07:06 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:07:29,900] INFO 127.0.0.1 - - [11/Nov/2020:01:07:29 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:07:48,134] INFO 127.0.0.1 - - [11/Nov/2020:01:07:48 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:08:04,653] INFO 127.0.0.1 - - [11/Nov/2020:01:08:04 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:08:42,340] INFO 127.0.0.1 - - [11/Nov/2020:01:08:42 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:08:59,617] INFO 127.0.0.1 - - [11/Nov/2020:01:08:59 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:09:17,814] INFO 127.0.0.1 - - [11/Nov/2020:01:09:17 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:09:38,246] INFO 127.0.0.1 - - [11/Nov/2020:01:09:38 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:09:59,880] INFO 127.0.0.1 - - [11/Nov/2020:01:09:59 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:10:22,026] INFO 127.0.0.1 - - [11/Nov/2020:01:10:22 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:10:45,099] INFO 127.0.0.1 - - [11/Nov/2020:01:10:45 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:11:01,964] INFO 127.0.0.1 - - [11/Nov/2020:01:11:01 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:11:03,244] INFO Stopped NetworkTrafficServerConnector@43738a82{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-11-10 17:11:03,245] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2020-11-10 17:11:03,246] INFO Stopped o.e.j.s.ServletContextHandler@2c4d1ac{/ws,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 17:11:03,251] INFO Stopped o.e.j.s.ServletContextHandler@7f0d96f2{/,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 17:11:03,252] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 17:11:03,252] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 17:11:03,253] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 17:11:03,253] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 17:11:03,254] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 17:11:03,255] INFO Kafka store producer shut down (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 17:11:03,256] INFO Kafka store shut down complete (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 17:11:03,256] ERROR Unexpected exception in schema registry group processing thread (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
org.apache.kafka.common.errors.WakeupException
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.maybeTriggerWakeup(ConsumerNetworkClient.java:514)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:278)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:227)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator.poll(SchemaRegistryCoordinator.java:124)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector$1.run(KafkaGroupLeaderElector.java:202)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-11-10 17:11:08,435] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	debug = false
	host.name = 192.168.0.105
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	kafkastore.zk.session.timeout.ms = 30000
	leader.eligibility = true
	listeners = [http://0.0.0.0:8081]
	master.eligibility = null
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2020-11-10 17:11:08,477] INFO Logging initialized @404ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2020-11-10 17:11:08,485] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2020-11-10 17:11:08,555] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.ApplicationServer)
[2020-11-10 17:11:09,028] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 17:11:09,028] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 17:11:09,029] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 17:11:09,032] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 17:11:09,045] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 17:11:09,050] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 17:11:09,101] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 17:11:09,144] INFO Seeking to beginning for all partitions (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 17:11:09,144] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 17:11:09,145] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 17:11:09,206] INFO Wait to catch up until the offset at 4 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 17:11:09,221] INFO Reached offset at 4 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 17:11:09,222] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 17:11:09,261] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-e5651074-9588-4178-b899-e030d37abd45', leaderIdentity=version=1,host=192.168.0.105,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2020-11-10 17:11:09,269] INFO Wait to catch up until the offset at 5 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 17:11:09,270] INFO Reached offset at 5 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 17:11:09,401] INFO jetty-9.4.30.v20200611; built: 2020-06-11T12:34:51.929Z; git: 271836e4c1f4612f12b7bb13ef5a92a927634b0d; jvm 1.8.0_265-b01 (org.eclipse.jetty.server.Server)
[2020-11-10 17:11:09,429] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2020-11-10 17:11:09,429] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2020-11-10 17:11:09,430] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session)
[2020-11-10 17:11:09,846] INFO HV000001: Hibernate Validator 6.1.2.Final (org.hibernate.validator.internal.util.Version)
[2020-11-10 17:11:10,040] INFO Started o.e.j.s.ServletContextHandler@7f0d96f2{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 17:11:10,051] INFO Started o.e.j.s.ServletContextHandler@2c4d1ac{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 17:11:10,063] INFO Started NetworkTrafficServerConnector@43738a82{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-11-10 17:11:10,064] INFO Started @1993ms (org.eclipse.jetty.server.Server)
[2020-11-10 17:11:10,064] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2020-11-10 17:11:24,314] INFO 127.0.0.1 - - [11/Nov/2020:01:11:24 +0000] "GET / HTTP/1.1" 200 2  94 (io.confluent.rest-utils.requests)
[2020-11-10 17:11:45,978] INFO 127.0.0.1 - - [11/Nov/2020:01:11:45 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:12:02,983] INFO 127.0.0.1 - - [11/Nov/2020:01:12:02 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:12:19,730] INFO 127.0.0.1 - - [11/Nov/2020:01:12:19 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 17:12:42,899] INFO 127.0.0.1 - - [11/Nov/2020:01:12:42 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:13:05,908] INFO 127.0.0.1 - - [11/Nov/2020:01:13:05 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:13:26,185] INFO 127.0.0.1 - - [11/Nov/2020:01:13:26 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:13:46,570] INFO 127.0.0.1 - - [11/Nov/2020:01:13:46 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 17:14:05,411] INFO 127.0.0.1 - - [11/Nov/2020:01:14:05 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:14:22,825] INFO 127.0.0.1 - - [11/Nov/2020:01:14:22 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 17:14:39,788] INFO 127.0.0.1 - - [11/Nov/2020:01:14:39 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 17:14:57,894] INFO 127.0.0.1 - - [11/Nov/2020:01:14:57 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:15:16,715] INFO 127.0.0.1 - - [11/Nov/2020:01:15:16 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:15:34,463] INFO 127.0.0.1 - - [11/Nov/2020:01:15:34 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:15:55,764] INFO 127.0.0.1 - - [11/Nov/2020:01:15:55 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 17:16:13,801] INFO 127.0.0.1 - - [11/Nov/2020:01:16:13 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 17:16:33,610] INFO 127.0.0.1 - - [11/Nov/2020:01:16:33 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:16:56,312] INFO 127.0.0.1 - - [11/Nov/2020:01:16:56 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 17:17:16,145] INFO 127.0.0.1 - - [11/Nov/2020:01:17:16 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:17:36,155] INFO 127.0.0.1 - - [11/Nov/2020:01:17:36 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:17:56,250] INFO 127.0.0.1 - - [11/Nov/2020:01:17:56 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:18:18,647] INFO 127.0.0.1 - - [11/Nov/2020:01:18:18 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:18:37,506] INFO 127.0.0.1 - - [11/Nov/2020:01:18:37 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:19:00,426] INFO 127.0.0.1 - - [11/Nov/2020:01:19:00 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 17:19:16,759] INFO 127.0.0.1 - - [11/Nov/2020:01:19:16 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:19:35,965] INFO 127.0.0.1 - - [11/Nov/2020:01:19:35 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 17:19:55,561] INFO 127.0.0.1 - - [11/Nov/2020:01:19:55 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 17:20:15,736] INFO 127.0.0.1 - - [11/Nov/2020:01:20:15 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:20:37,974] INFO 127.0.0.1 - - [11/Nov/2020:01:20:37 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 17:20:57,208] INFO 127.0.0.1 - - [11/Nov/2020:01:20:57 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:21:14,731] INFO 127.0.0.1 - - [11/Nov/2020:01:21:14 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:21:37,494] INFO 127.0.0.1 - - [11/Nov/2020:01:21:37 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 17:21:57,961] INFO 127.0.0.1 - - [11/Nov/2020:01:21:57 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 17:22:14,953] INFO 127.0.0.1 - - [11/Nov/2020:01:22:14 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:22:38,907] INFO 127.0.0.1 - - [11/Nov/2020:01:22:38 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:23:00,832] INFO 127.0.0.1 - - [11/Nov/2020:01:23:00 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:23:24,442] INFO 127.0.0.1 - - [11/Nov/2020:01:23:24 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:23:43,126] INFO 127.0.0.1 - - [11/Nov/2020:01:23:43 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:24:05,886] INFO 127.0.0.1 - - [11/Nov/2020:01:24:05 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:24:23,324] INFO 127.0.0.1 - - [11/Nov/2020:01:24:23 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:24:44,159] INFO 127.0.0.1 - - [11/Nov/2020:01:24:44 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:25:01,234] INFO 127.0.0.1 - - [11/Nov/2020:01:25:01 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:25:19,929] INFO 127.0.0.1 - - [11/Nov/2020:01:25:19 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 17:25:37,450] INFO 127.0.0.1 - - [11/Nov/2020:01:25:37 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 17:25:57,369] INFO 127.0.0.1 - - [11/Nov/2020:01:25:57 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:26:19,760] INFO 127.0.0.1 - - [11/Nov/2020:01:26:19 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:26:36,094] INFO 127.0.0.1 - - [11/Nov/2020:01:26:36 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 17:26:54,546] INFO 127.0.0.1 - - [11/Nov/2020:01:26:54 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 17:27:16,059] INFO 127.0.0.1 - - [11/Nov/2020:01:27:16 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:27:37,742] INFO 127.0.0.1 - - [11/Nov/2020:01:27:37 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:27:55,737] INFO 127.0.0.1 - - [11/Nov/2020:01:27:55 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:28:15,380] INFO 127.0.0.1 - - [11/Nov/2020:01:28:15 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:28:34,082] INFO 127.0.0.1 - - [11/Nov/2020:01:28:34 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:28:56,771] INFO 127.0.0.1 - - [11/Nov/2020:01:28:56 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:29:12,871] INFO 127.0.0.1 - - [11/Nov/2020:01:29:12 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:29:36,202] INFO 127.0.0.1 - - [11/Nov/2020:01:29:36 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 17:29:58,135] INFO 127.0.0.1 - - [11/Nov/2020:01:29:58 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:30:16,962] INFO 127.0.0.1 - - [11/Nov/2020:01:30:16 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 17:30:39,658] INFO 127.0.0.1 - - [11/Nov/2020:01:30:39 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:31:02,280] INFO 127.0.0.1 - - [11/Nov/2020:01:31:02 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:31:18,788] INFO 127.0.0.1 - - [11/Nov/2020:01:31:18 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:31:37,211] INFO 127.0.0.1 - - [11/Nov/2020:01:31:37 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:31:55,345] INFO 127.0.0.1 - - [11/Nov/2020:01:31:55 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:32:15,006] INFO 127.0.0.1 - - [11/Nov/2020:01:32:15 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 17:32:34,455] INFO 127.0.0.1 - - [11/Nov/2020:01:32:34 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:32:54,975] INFO 127.0.0.1 - - [11/Nov/2020:01:32:54 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 17:33:12,259] INFO 127.0.0.1 - - [11/Nov/2020:01:33:12 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:33:28,702] INFO 127.0.0.1 - - [11/Nov/2020:01:33:28 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:33:52,541] INFO 127.0.0.1 - - [11/Nov/2020:01:33:52 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 17:34:10,881] INFO 127.0.0.1 - - [11/Nov/2020:01:34:10 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 17:34:32,935] INFO 127.0.0.1 - - [11/Nov/2020:01:34:32 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:34:56,570] INFO 127.0.0.1 - - [11/Nov/2020:01:34:56 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:35:14,906] INFO 127.0.0.1 - - [11/Nov/2020:01:35:14 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:35:38,204] INFO 127.0.0.1 - - [11/Nov/2020:01:35:38 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:35:54,343] INFO 127.0.0.1 - - [11/Nov/2020:01:35:54 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 17:36:14,310] INFO 127.0.0.1 - - [11/Nov/2020:01:36:14 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 17:36:37,543] INFO 127.0.0.1 - - [11/Nov/2020:01:36:37 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:37:01,114] INFO 127.0.0.1 - - [11/Nov/2020:01:37:01 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 17:37:25,024] INFO 127.0.0.1 - - [11/Nov/2020:01:37:25 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:37:47,497] INFO 127.0.0.1 - - [11/Nov/2020:01:37:47 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-11-10 17:38:06,425] INFO 127.0.0.1 - - [11/Nov/2020:01:38:06 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:38:29,363] INFO 127.0.0.1 - - [11/Nov/2020:01:38:29 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:38:45,753] INFO 127.0.0.1 - - [11/Nov/2020:01:38:45 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 17:39:02,796] INFO Stopped NetworkTrafficServerConnector@43738a82{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-11-10 17:39:02,797] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2020-11-10 17:39:02,798] INFO Stopped o.e.j.s.ServletContextHandler@2c4d1ac{/ws,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 17:39:02,803] INFO Stopped o.e.j.s.ServletContextHandler@7f0d96f2{/,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 17:39:02,804] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 17:39:02,804] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 17:39:02,804] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 17:39:02,805] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 17:39:02,806] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 17:39:02,807] INFO Kafka store producer shut down (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 17:39:02,807] INFO Kafka store shut down complete (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 17:39:02,808] ERROR Unexpected exception in schema registry group processing thread (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
org.apache.kafka.common.errors.WakeupException
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.maybeTriggerWakeup(ConsumerNetworkClient.java:514)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:278)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:227)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator.poll(SchemaRegistryCoordinator.java:124)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector$1.run(KafkaGroupLeaderElector.java:202)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-11-10 19:50:21,938] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	debug = false
	host.name = 192.168.0.105
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	kafkastore.zk.session.timeout.ms = 30000
	leader.eligibility = true
	listeners = [http://0.0.0.0:8081]
	master.eligibility = null
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2020-11-10 19:50:21,980] INFO Logging initialized @3791ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2020-11-10 19:50:21,988] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2020-11-10 19:50:22,055] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.ApplicationServer)
[2020-11-10 19:50:44,536] ERROR Error starting the schema registry (io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication)
io.confluent.kafka.schemaregistry.exceptions.SchemaRegistryException: Failed to get Kafka cluster ID
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.kafkaClusterId(KafkaSchemaRegistry.java:1277)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.<init>(KafkaSchemaRegistry.java:158)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.initSchemaRegistry(SchemaRegistryRestApplication.java:69)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.configureBaseApplication(SchemaRegistryRestApplication.java:88)
	at io.confluent.rest.Application.configureHandler(Application.java:254)
	at io.confluent.rest.ApplicationServer.doStart(ApplicationServer.java:227)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:72)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain.main(SchemaRegistryMain.java:43)
Caused by: java.util.concurrent.TimeoutException
	at org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.kafkaClusterId(KafkaSchemaRegistry.java:1275)
	... 7 more
[2020-11-10 19:51:47,722] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	debug = false
	host.name = 192.168.0.105
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	kafkastore.zk.session.timeout.ms = 30000
	leader.eligibility = true
	listeners = [http://0.0.0.0:8081]
	master.eligibility = null
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2020-11-10 19:51:47,768] INFO Logging initialized @403ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2020-11-10 19:51:47,777] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2020-11-10 19:51:47,848] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.ApplicationServer)
[2020-11-10 19:51:48,335] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 19:51:48,335] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 19:51:48,336] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 19:51:48,339] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 19:51:48,355] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 19:51:48,359] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 19:51:48,424] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 19:51:48,471] INFO Seeking to beginning for all partitions (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 19:51:48,471] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 19:51:48,472] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 19:51:48,539] INFO Wait to catch up until the offset at 5 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 19:51:48,554] INFO Reached offset at 5 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 19:51:48,556] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 19:51:48,594] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-e9f3bc0b-2df9-417b-bc0a-d35b45940c6e', leaderIdentity=version=1,host=192.168.0.105,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2020-11-10 19:51:48,602] INFO Wait to catch up until the offset at 6 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 19:51:48,603] INFO Reached offset at 6 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 19:51:48,744] INFO jetty-9.4.30.v20200611; built: 2020-06-11T12:34:51.929Z; git: 271836e4c1f4612f12b7bb13ef5a92a927634b0d; jvm 1.8.0_265-b01 (org.eclipse.jetty.server.Server)
[2020-11-10 19:51:48,770] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2020-11-10 19:51:48,770] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2020-11-10 19:51:48,771] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session)
[2020-11-10 19:51:49,210] INFO HV000001: Hibernate Validator 6.1.2.Final (org.hibernate.validator.internal.util.Version)
[2020-11-10 19:51:49,435] INFO Started o.e.j.s.ServletContextHandler@36328d33{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 19:51:49,445] INFO Started o.e.j.s.ServletContextHandler@c94fd30{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 19:51:49,458] INFO Started NetworkTrafficServerConnector@43738a82{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-11-10 19:51:49,459] INFO Started @2096ms (org.eclipse.jetty.server.Server)
[2020-11-10 19:51:49,459] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2020-11-10 19:51:59,414] INFO 127.0.0.1 - - [11/Nov/2020:03:51:59 +0000] "GET / HTTP/1.1" 200 2  96 (io.confluent.rest-utils.requests)
[2020-11-10 19:52:17,297] INFO 127.0.0.1 - - [11/Nov/2020:03:52:17 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 19:52:18,602] INFO Rebalance started (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2020-11-10 19:52:18,604] ERROR Found duplicate URLs for schema registry group members. This indicates a misconfiguration and is common when executing in containers. Use the host.name configuration to set each instance's advertised host name to a value that is routable from all other schema registry instances. (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2020-11-10 19:52:18,606] INFO Finished rebalance with leader election result: Assignment{version=1, error=1, leader='sr-1-e9f3bc0b-2df9-417b-bc0a-d35b45940c6e', leaderIdentity=version=1,host=192.168.0.105,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2020-11-10 19:52:18,607] ERROR Unexpected exception in schema registry group processing thread (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
java.lang.IllegalStateException: The schema registry group contained multiple members advertising the same URL. Verify that each instance has a unique, routable listener by setting the 'listeners' configuration. This error may happen if executing in containers where the default hostname is 'localhost'.
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector.onAssigned(KafkaGroupLeaderElector.java:248)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator.onJoinComplete(SchemaRegistryCoordinator.java:149)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.joinGroupIfNeeded(AbstractCoordinator.java:451)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureActiveGroup(AbstractCoordinator.java:367)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureActiveGroup(AbstractCoordinator.java:347)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator.poll(SchemaRegistryCoordinator.java:113)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector$1.run(KafkaGroupLeaderElector.java:202)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-11-10 19:52:40,625] INFO 127.0.0.1 - - [11/Nov/2020:03:52:40 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 19:52:58,211] INFO 127.0.0.1 - - [11/Nov/2020:03:52:58 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 19:53:14,244] INFO 127.0.0.1 - - [11/Nov/2020:03:53:14 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 19:53:17,661] INFO Stopped NetworkTrafficServerConnector@43738a82{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-11-10 19:53:17,661] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2020-11-10 19:53:17,663] INFO Stopped o.e.j.s.ServletContextHandler@c94fd30{/ws,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 19:53:17,668] INFO Stopped o.e.j.s.ServletContextHandler@36328d33{/,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 19:53:17,669] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 19:53:17,669] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 19:53:17,670] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 19:53:17,670] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 19:53:17,671] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 19:53:17,672] INFO Kafka store producer shut down (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 19:53:17,672] INFO Kafka store shut down complete (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 19:54:48,326] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	debug = false
	host.name = 192.168.0.105
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	kafkastore.zk.session.timeout.ms = 30000
	leader.eligibility = true
	listeners = [http://0.0.0.0:8081]
	master.eligibility = null
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2020-11-10 19:54:48,371] INFO Logging initialized @402ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2020-11-10 19:54:48,381] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2020-11-10 19:54:48,451] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.ApplicationServer)
[2020-11-10 19:54:48,929] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 19:54:48,929] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 19:54:48,929] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 19:54:48,933] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 19:54:48,953] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 19:54:48,960] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 19:54:49,023] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 19:54:49,062] INFO Seeking to beginning for all partitions (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 19:54:49,063] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 19:54:49,064] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 19:54:49,141] INFO Wait to catch up until the offset at 8 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 19:54:49,153] INFO Reached offset at 8 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 19:54:49,154] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 19:54:49,210] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-f751d2eb-ed63-4aa4-848c-53163ad280bf', leaderIdentity=version=1,host=192.168.0.105,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2020-11-10 19:54:49,218] INFO Wait to catch up until the offset at 9 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 19:54:49,218] INFO Reached offset at 9 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 19:54:49,342] INFO jetty-9.4.30.v20200611; built: 2020-06-11T12:34:51.929Z; git: 271836e4c1f4612f12b7bb13ef5a92a927634b0d; jvm 1.8.0_265-b01 (org.eclipse.jetty.server.Server)
[2020-11-10 19:54:49,369] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2020-11-10 19:54:49,370] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2020-11-10 19:54:49,371] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session)
[2020-11-10 19:54:49,776] INFO HV000001: Hibernate Validator 6.1.2.Final (org.hibernate.validator.internal.util.Version)
[2020-11-10 19:54:49,978] INFO Started o.e.j.s.ServletContextHandler@36328d33{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 19:54:49,988] INFO Started o.e.j.s.ServletContextHandler@c94fd30{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 19:54:50,004] INFO Started NetworkTrafficServerConnector@43738a82{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-11-10 19:54:50,005] INFO Started @2039ms (org.eclipse.jetty.server.Server)
[2020-11-10 19:54:50,005] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2020-11-10 19:55:30,956] INFO 127.0.0.1 - - [11/Nov/2020:03:55:30 +0000] "GET / HTTP/1.1" 200 2  81 (io.confluent.rest-utils.requests)
[2020-11-10 19:55:54,278] INFO 127.0.0.1 - - [11/Nov/2020:03:55:54 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 19:56:17,235] INFO 127.0.0.1 - - [11/Nov/2020:03:56:17 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 19:56:40,651] INFO 127.0.0.1 - - [11/Nov/2020:03:56:40 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 19:56:58,921] INFO 127.0.0.1 - - [11/Nov/2020:03:56:58 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 19:57:22,654] INFO 127.0.0.1 - - [11/Nov/2020:03:57:22 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 19:57:39,232] INFO 127.0.0.1 - - [11/Nov/2020:03:57:39 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 19:58:02,189] INFO 127.0.0.1 - - [11/Nov/2020:03:58:02 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 19:58:19,357] INFO 127.0.0.1 - - [11/Nov/2020:03:58:19 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 19:58:36,587] INFO 127.0.0.1 - - [11/Nov/2020:03:58:36 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 19:58:47,279] INFO Stopped NetworkTrafficServerConnector@43738a82{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-11-10 19:58:47,279] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2020-11-10 19:58:47,280] INFO Stopped o.e.j.s.ServletContextHandler@c94fd30{/ws,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 19:58:47,285] INFO Stopped o.e.j.s.ServletContextHandler@36328d33{/,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 19:58:47,286] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 19:58:47,286] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 19:58:47,287] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 19:58:47,287] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 19:58:47,288] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 19:58:47,289] INFO Kafka store producer shut down (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 19:58:47,290] INFO Kafka store shut down complete (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 19:58:47,290] ERROR Unexpected exception in schema registry group processing thread (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
org.apache.kafka.common.errors.WakeupException
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.maybeTriggerWakeup(ConsumerNetworkClient.java:514)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:278)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:227)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator.poll(SchemaRegistryCoordinator.java:124)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector$1.run(KafkaGroupLeaderElector.java:202)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-11-10 20:32:14,348] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	debug = false
	host.name = 192.168.0.105
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	kafkastore.zk.session.timeout.ms = 30000
	leader.eligibility = true
	listeners = [http://0.0.0.0:8081]
	master.eligibility = null
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2020-11-10 20:32:14,389] INFO Logging initialized @412ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2020-11-10 20:32:14,398] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2020-11-10 20:32:14,468] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.ApplicationServer)
[2020-11-10 20:33:14,693] ERROR Error starting the schema registry (io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication)
io.confluent.kafka.schemaregistry.exceptions.SchemaRegistryException: Failed to get Kafka cluster ID
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.kafkaClusterId(KafkaSchemaRegistry.java:1277)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.<init>(KafkaSchemaRegistry.java:158)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.initSchemaRegistry(SchemaRegistryRestApplication.java:69)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.configureBaseApplication(SchemaRegistryRestApplication.java:88)
	at io.confluent.rest.Application.configureHandler(Application.java:254)
	at io.confluent.rest.ApplicationServer.doStart(ApplicationServer.java:227)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:72)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain.main(SchemaRegistryMain.java:43)
Caused by: java.util.concurrent.TimeoutException
	at org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.kafkaClusterId(KafkaSchemaRegistry.java:1275)
	... 7 more
[2020-11-10 20:33:26,981] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	debug = false
	host.name = 192.168.0.105
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	kafkastore.zk.session.timeout.ms = 30000
	leader.eligibility = true
	listeners = [http://0.0.0.0:8081]
	master.eligibility = null
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2020-11-10 20:33:27,021] INFO Logging initialized @393ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2020-11-10 20:33:27,028] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2020-11-10 20:33:27,098] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.ApplicationServer)
[2020-11-10 20:34:27,338] ERROR Error starting the schema registry (io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication)
io.confluent.kafka.schemaregistry.exceptions.SchemaRegistryException: Failed to get Kafka cluster ID
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.kafkaClusterId(KafkaSchemaRegistry.java:1277)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.<init>(KafkaSchemaRegistry.java:158)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.initSchemaRegistry(SchemaRegistryRestApplication.java:69)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.configureBaseApplication(SchemaRegistryRestApplication.java:88)
	at io.confluent.rest.Application.configureHandler(Application.java:254)
	at io.confluent.rest.ApplicationServer.doStart(ApplicationServer.java:227)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:72)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain.main(SchemaRegistryMain.java:43)
Caused by: java.util.concurrent.TimeoutException
	at org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.kafkaClusterId(KafkaSchemaRegistry.java:1275)
	... 7 more
[2020-11-10 20:34:35,890] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	debug = false
	host.name = 192.168.0.105
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	kafkastore.zk.session.timeout.ms = 30000
	leader.eligibility = true
	listeners = [http://0.0.0.0:8081]
	master.eligibility = null
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2020-11-10 20:34:35,931] INFO Logging initialized @394ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2020-11-10 20:34:35,938] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2020-11-10 20:34:36,003] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.ApplicationServer)
[2020-11-10 20:35:36,219] ERROR Error starting the schema registry (io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication)
io.confluent.kafka.schemaregistry.exceptions.SchemaRegistryException: Failed to get Kafka cluster ID
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.kafkaClusterId(KafkaSchemaRegistry.java:1277)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.<init>(KafkaSchemaRegistry.java:158)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.initSchemaRegistry(SchemaRegistryRestApplication.java:69)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.configureBaseApplication(SchemaRegistryRestApplication.java:88)
	at io.confluent.rest.Application.configureHandler(Application.java:254)
	at io.confluent.rest.ApplicationServer.doStart(ApplicationServer.java:227)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:72)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain.main(SchemaRegistryMain.java:43)
Caused by: java.util.concurrent.TimeoutException
	at org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.kafkaClusterId(KafkaSchemaRegistry.java:1275)
	... 7 more
[2020-11-10 20:35:43,125] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	debug = false
	host.name = 192.168.0.105
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	kafkastore.zk.session.timeout.ms = 30000
	leader.eligibility = true
	listeners = [http://0.0.0.0:8081]
	master.eligibility = null
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2020-11-10 20:35:43,167] INFO Logging initialized @390ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2020-11-10 20:35:43,176] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2020-11-10 20:35:43,245] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.ApplicationServer)
[2020-11-10 20:36:43,463] ERROR Error starting the schema registry (io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication)
io.confluent.kafka.schemaregistry.exceptions.SchemaRegistryException: Failed to get Kafka cluster ID
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.kafkaClusterId(KafkaSchemaRegistry.java:1277)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.<init>(KafkaSchemaRegistry.java:158)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.initSchemaRegistry(SchemaRegistryRestApplication.java:69)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.configureBaseApplication(SchemaRegistryRestApplication.java:88)
	at io.confluent.rest.Application.configureHandler(Application.java:254)
	at io.confluent.rest.ApplicationServer.doStart(ApplicationServer.java:227)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:72)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain.main(SchemaRegistryMain.java:43)
Caused by: java.util.concurrent.TimeoutException
	at org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.kafkaClusterId(KafkaSchemaRegistry.java:1275)
	... 7 more
[2020-11-10 20:39:19,339] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	debug = false
	host.name = 192.168.0.105
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	kafkastore.zk.session.timeout.ms = 30000
	leader.eligibility = true
	listeners = [http://0.0.0.0:8081]
	master.eligibility = null
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2020-11-10 20:39:19,380] INFO Logging initialized @396ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2020-11-10 20:39:19,388] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2020-11-10 20:39:19,457] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.ApplicationServer)
[2020-11-10 20:39:19,921] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 20:39:19,921] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 20:39:19,921] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 20:39:19,924] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 20:39:19,945] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 20:39:19,951] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 20:39:20,009] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 20:39:20,051] INFO Seeking to beginning for all partitions (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 20:39:20,052] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 20:39:20,053] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 20:39:20,144] INFO Wait to catch up until the offset at 10 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 20:39:20,144] INFO Reached offset at 10 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 20:39:20,145] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 20:39:20,203] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-db311ecb-f0b4-4213-b2c2-dca3520a254d', leaderIdentity=version=1,host=192.168.0.105,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2020-11-10 20:39:20,212] INFO Wait to catch up until the offset at 11 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 20:39:20,212] INFO Reached offset at 11 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 20:39:20,337] INFO jetty-9.4.30.v20200611; built: 2020-06-11T12:34:51.929Z; git: 271836e4c1f4612f12b7bb13ef5a92a927634b0d; jvm 1.8.0_265-b01 (org.eclipse.jetty.server.Server)
[2020-11-10 20:39:20,363] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2020-11-10 20:39:20,363] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2020-11-10 20:39:20,365] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session)
[2020-11-10 20:39:20,781] INFO HV000001: Hibernate Validator 6.1.2.Final (org.hibernate.validator.internal.util.Version)
[2020-11-10 20:39:20,978] INFO Started o.e.j.s.ServletContextHandler@36328d33{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 20:39:20,989] INFO Started o.e.j.s.ServletContextHandler@c94fd30{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 20:39:21,002] INFO Started NetworkTrafficServerConnector@43738a82{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-11-10 20:39:21,002] INFO Started @2020ms (org.eclipse.jetty.server.Server)
[2020-11-10 20:39:21,002] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2020-11-10 20:39:37,010] INFO 127.0.0.1 - - [11/Nov/2020:04:39:36 +0000] "GET / HTTP/1.1" 200 2  91 (io.confluent.rest-utils.requests)
[2020-11-10 20:39:58,156] INFO 127.0.0.1 - - [11/Nov/2020:04:39:58 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 20:40:15,091] INFO 127.0.0.1 - - [11/Nov/2020:04:40:15 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 20:40:32,884] INFO 127.0.0.1 - - [11/Nov/2020:04:40:32 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 20:40:49,781] INFO 127.0.0.1 - - [11/Nov/2020:04:40:49 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 20:41:12,413] INFO 127.0.0.1 - - [11/Nov/2020:04:41:12 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 20:41:36,281] INFO 127.0.0.1 - - [11/Nov/2020:04:41:36 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 20:41:56,291] INFO 127.0.0.1 - - [11/Nov/2020:04:41:56 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 20:42:20,216] INFO 127.0.0.1 - - [11/Nov/2020:04:42:20 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 20:42:26,320] INFO Rebalance started (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2020-11-10 20:42:26,323] ERROR Found duplicate URLs for schema registry group members. This indicates a misconfiguration and is common when executing in containers. Use the host.name configuration to set each instance's advertised host name to a value that is routable from all other schema registry instances. (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2020-11-10 20:42:26,326] INFO Finished rebalance with leader election result: Assignment{version=1, error=1, leader='sr-1-feccf4c5-2ba3-4584-accf-8bbe7caec507', leaderIdentity=version=1,host=192.168.0.105,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2020-11-10 20:42:26,326] ERROR Unexpected exception in schema registry group processing thread (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
java.lang.IllegalStateException: The schema registry group contained multiple members advertising the same URL. Verify that each instance has a unique, routable listener by setting the 'listeners' configuration. This error may happen if executing in containers where the default hostname is 'localhost'.
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector.onAssigned(KafkaGroupLeaderElector.java:248)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator.onJoinComplete(SchemaRegistryCoordinator.java:149)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.joinGroupIfNeeded(AbstractCoordinator.java:451)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureActiveGroup(AbstractCoordinator.java:367)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureActiveGroup(AbstractCoordinator.java:347)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator.poll(SchemaRegistryCoordinator.java:113)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector$1.run(KafkaGroupLeaderElector.java:202)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-11-10 20:42:41,698] INFO 127.0.0.1 - - [11/Nov/2020:04:42:41 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 20:43:02,071] INFO 127.0.0.1 - - [11/Nov/2020:04:43:02 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 20:43:03,354] INFO 127.0.0.1 - - [11/Nov/2020:04:43:03 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 20:43:22,688] INFO Stopped NetworkTrafficServerConnector@43738a82{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-11-10 20:43:22,689] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2020-11-10 20:43:22,690] INFO Stopped o.e.j.s.ServletContextHandler@c94fd30{/ws,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 20:43:22,694] INFO Stopped o.e.j.s.ServletContextHandler@36328d33{/,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 20:43:22,695] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 20:43:22,695] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 20:43:22,696] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 20:43:22,696] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 20:43:22,697] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 20:43:22,698] INFO Kafka store producer shut down (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 20:43:22,698] INFO Kafka store shut down complete (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 20:43:30,381] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	debug = false
	host.name = 192.168.0.105
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	kafkastore.zk.session.timeout.ms = 30000
	leader.eligibility = true
	listeners = [http://0.0.0.0:8081]
	master.eligibility = null
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2020-11-10 20:43:30,423] INFO Logging initialized @405ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2020-11-10 20:43:30,431] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2020-11-10 20:43:30,501] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.ApplicationServer)
[2020-11-10 20:43:30,967] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 20:43:30,967] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 20:43:30,967] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 20:43:30,971] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 20:43:30,987] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 20:43:30,993] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 20:43:31,044] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 20:43:31,085] INFO Seeking to beginning for all partitions (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 20:43:31,086] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 20:43:31,087] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 20:43:31,154] INFO Wait to catch up until the offset at 13 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 20:43:31,169] INFO Reached offset at 13 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 20:43:31,170] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 20:43:31,779] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-8c8e052b-ce80-4d9e-baaa-e9c0b4a6f7ea', leaderIdentity=version=1,host=192.168.0.105,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2020-11-10 20:43:31,788] INFO Wait to catch up until the offset at 14 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 20:43:31,789] INFO Reached offset at 14 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 20:43:31,921] INFO jetty-9.4.30.v20200611; built: 2020-06-11T12:34:51.929Z; git: 271836e4c1f4612f12b7bb13ef5a92a927634b0d; jvm 1.8.0_265-b01 (org.eclipse.jetty.server.Server)
[2020-11-10 20:43:31,953] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2020-11-10 20:43:31,953] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2020-11-10 20:43:31,954] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session)
[2020-11-10 20:43:32,368] INFO HV000001: Hibernate Validator 6.1.2.Final (org.hibernate.validator.internal.util.Version)
[2020-11-10 20:43:32,565] INFO Started o.e.j.s.ServletContextHandler@36328d33{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 20:43:32,575] INFO Started o.e.j.s.ServletContextHandler@c94fd30{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 20:43:32,587] INFO Started NetworkTrafficServerConnector@43738a82{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-11-10 20:43:32,587] INFO Started @2571ms (org.eclipse.jetty.server.Server)
[2020-11-10 20:43:32,587] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2020-11-10 20:43:46,933] INFO 127.0.0.1 - - [11/Nov/2020:04:43:46 +0000] "GET / HTTP/1.1" 200 2  88 (io.confluent.rest-utils.requests)
[2020-11-10 20:44:03,402] INFO 127.0.0.1 - - [11/Nov/2020:04:44:03 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-11-10 20:44:20,506] INFO 127.0.0.1 - - [11/Nov/2020:04:44:20 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 20:44:32,592] ERROR Request Failed with exception  (io.confluent.rest.exceptions.DebuggableExceptionMapper)
io.confluent.rest.exceptions.RestNotFoundException: Subject 'default_ksql_processing_log-value' not found.
	at io.confluent.kafka.schemaregistry.rest.exceptions.Errors.subjectNotFoundException(Errors.java:69)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.listVersions(SubjectVersionsResource.java:197)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$TypeOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:219)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:469)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:391)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:80)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:253)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:232)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.ServletContainer.serviceImpl(ServletContainer.java:386)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:561)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:502)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:439)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1618)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:549)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1610)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1369)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:489)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1580)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1284)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:767)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:501)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:272)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:135)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
	at java.lang.Thread.run(Thread.java:748)
[2020-11-10 20:44:32,596] INFO 127.0.0.1 - - [11/Nov/2020:04:44:32 +0000] "GET /subjects/default_ksql_processing_log-value/versions HTTP/1.1" 404 87  30 (io.confluent.rest-utils.requests)
[2020-11-10 20:44:40,066] INFO 127.0.0.1 - - [11/Nov/2020:04:44:40 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-11-10 20:44:56,429] INFO Stopped NetworkTrafficServerConnector@43738a82{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-11-10 20:44:56,429] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2020-11-10 20:44:56,431] INFO Stopped o.e.j.s.ServletContextHandler@c94fd30{/ws,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 20:44:56,435] INFO Stopped o.e.j.s.ServletContextHandler@36328d33{/,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-11-10 20:44:56,436] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-11-10 20:44:56,437] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 20:44:56,437] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 20:44:56,437] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 20:44:56,439] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-11-10 20:44:56,440] INFO Kafka store producer shut down (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 20:44:56,440] INFO Kafka store shut down complete (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-11-10 20:44:56,440] ERROR Unexpected exception in schema registry group processing thread (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
org.apache.kafka.common.errors.WakeupException
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.maybeTriggerWakeup(ConsumerNetworkClient.java:514)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:278)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:227)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator.poll(SchemaRegistryCoordinator.java:124)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector$1.run(KafkaGroupLeaderElector.java:202)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-12-07 13:20:51,262] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	debug = false
	host.name = 192.168.0.104
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	kafkastore.zk.session.timeout.ms = 30000
	leader.eligibility = true
	listeners = [http://0.0.0.0:8081]
	master.eligibility = null
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2020-12-07 13:20:51,310] INFO Logging initialized @4332ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2020-12-07 13:20:51,319] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2020-12-07 13:20:51,391] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.ApplicationServer)
[2020-12-07 13:20:51,979] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-12-07 13:20:51,980] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-12-07 13:20:51,980] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-12-07 13:20:51,983] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:20:51,995] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:20:51,999] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:20:52,068] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 13:20:52,111] INFO Seeking to beginning for all partitions (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 13:20:52,112] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 13:20:52,113] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 13:20:52,184] INFO Wait to catch up until the offset at 8 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:20:52,220] INFO Reached offset at 8 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:20:52,221] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-12-07 13:20:52,255] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-c053c707-6c0c-4442-b899-ec75343f5cf5', leaderIdentity=version=1,host=192.168.0.104,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2020-12-07 13:20:52,262] INFO Wait to catch up until the offset at 9 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:20:52,262] INFO Reached offset at 9 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:20:52,389] INFO jetty-9.4.30.v20200611; built: 2020-06-11T12:34:51.929Z; git: 271836e4c1f4612f12b7bb13ef5a92a927634b0d; jvm 1.8.0_265-b01 (org.eclipse.jetty.server.Server)
[2020-12-07 13:20:52,416] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2020-12-07 13:20:52,416] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2020-12-07 13:20:52,418] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session)
[2020-12-07 13:20:52,855] INFO HV000001: Hibernate Validator 6.1.2.Final (org.hibernate.validator.internal.util.Version)
[2020-12-07 13:20:53,066] INFO Started o.e.j.s.ServletContextHandler@76f4b65{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-12-07 13:20:53,076] INFO Started o.e.j.s.ServletContextHandler@34c01041{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-12-07 13:20:53,089] INFO Started NetworkTrafficServerConnector@43738a82{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-12-07 13:20:53,089] INFO Started @6113ms (org.eclipse.jetty.server.Server)
[2020-12-07 13:20:53,089] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2020-12-07 13:20:58,821] INFO 127.0.0.1 - - [07/Dec/2020:21:20:58 +0000] "GET / HTTP/1.1" 200 2  103 (io.confluent.rest-utils.requests)
[2020-12-07 13:21:01,202] INFO Registering new schema: subject Kafka-value, version null, id null, type null (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2020-12-07 13:21:01,229] INFO Wait to catch up until the offset at 9 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:21:01,229] INFO Reached offset at 9 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:21:01,237] INFO Wait to catch up until the offset at 10 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:21:01,238] INFO Reached offset at 10 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:21:01,240] INFO 0:0:0:0:0:0:0:1 - - [07/Dec/2020:21:21:01 +0000] "POST /subjects/Kafka-value/versions HTTP/1.1" 200 13  84 (io.confluent.rest-utils.requests)
[2020-12-07 13:21:17,838] INFO 127.0.0.1 - - [07/Dec/2020:21:21:17 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-12-07 13:21:35,224] INFO 127.0.0.1 - - [07/Dec/2020:21:21:35 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:21:48,904] INFO 0:0:0:0:0:0:0:1 - - [07/Dec/2020:21:21:48 +0000] "GET /subjects HTTP/1.1" 200 37  51 (io.confluent.rest-utils.requests)
[2020-12-07 13:21:55,039] INFO 127.0.0.1 - - [07/Dec/2020:21:21:55 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:22:06,689] INFO 0:0:0:0:0:0:0:1 - - [07/Dec/2020:21:22:06 +0000] "GET /subjects/Kafka-value/versions HTTP/1.1" 200 3  5 (io.confluent.rest-utils.requests)
[2020-12-07 13:22:12,713] INFO 127.0.0.1 - - [07/Dec/2020:21:22:12 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:22:18,340] INFO 0:0:0:0:0:0:0:1 - - [07/Dec/2020:21:22:18 +0000] "GET /subjects/Kafka-value/versions/1 HTTP/1.1" 200 96  4 (io.confluent.rest-utils.requests)
[2020-12-07 13:22:35,004] INFO 127.0.0.1 - - [07/Dec/2020:21:22:35 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-12-07 13:22:52,314] INFO 127.0.0.1 - - [07/Dec/2020:21:22:52 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-12-07 13:23:02,973] INFO Registering new schema: subject Kafka-key, version null, id null, type null (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2020-12-07 13:23:02,974] INFO Wait to catch up until the offset at 10 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:23:02,974] INFO Reached offset at 10 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:23:02,976] INFO Wait to catch up until the offset at 11 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:23:02,977] INFO Reached offset at 11 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:23:02,978] INFO 0:0:0:0:0:0:0:1 - - [07/Dec/2020:21:23:02 +0000] "POST /subjects/Kafka-key/versions HTTP/1.1" 200 13  7 (io.confluent.rest-utils.requests)
[2020-12-07 13:23:09,977] INFO 127.0.0.1 - - [07/Dec/2020:21:23:09 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:23:28,605] INFO 127.0.0.1 - - [07/Dec/2020:21:23:28 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-12-07 13:23:50,472] INFO 127.0.0.1 - - [07/Dec/2020:21:23:50 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:24:12,360] INFO 127.0.0.1 - - [07/Dec/2020:21:24:12 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 13:24:30,438] INFO 127.0.0.1 - - [07/Dec/2020:21:24:30 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 13:24:50,337] INFO 127.0.0.1 - - [07/Dec/2020:21:24:50 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 13:25:09,275] INFO 127.0.0.1 - - [07/Dec/2020:21:25:09 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:25:27,054] INFO 127.0.0.1 - - [07/Dec/2020:21:25:27 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:25:44,709] INFO 127.0.0.1 - - [07/Dec/2020:21:25:44 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:26:06,552] INFO 127.0.0.1 - - [07/Dec/2020:21:26:06 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:26:27,401] INFO 127.0.0.1 - - [07/Dec/2020:21:26:27 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:26:37,306] INFO 0:0:0:0:0:0:0:1 - - [07/Dec/2020:21:26:37 +0000] "GET /subjects/Kafka-value/versions HTTP/1.1" 200 3  3 (io.confluent.rest-utils.requests)
[2020-12-07 13:26:41,055] INFO 0:0:0:0:0:0:0:1 - - [07/Dec/2020:21:26:41 +0000] "GET /subjects HTTP/1.1" 200 49  1 (io.confluent.rest-utils.requests)
[2020-12-07 13:26:43,712] INFO 127.0.0.1 - - [07/Dec/2020:21:26:43 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 13:27:01,494] INFO 127.0.0.1 - - [07/Dec/2020:21:27:01 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:27:17,976] INFO Stopped NetworkTrafficServerConnector@43738a82{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-12-07 13:27:17,976] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2020-12-07 13:27:17,978] INFO Stopped o.e.j.s.ServletContextHandler@34c01041{/ws,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-12-07 13:27:17,986] INFO Stopped o.e.j.s.ServletContextHandler@76f4b65{/,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-12-07 13:27:17,988] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-12-07 13:27:17,988] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 13:27:17,989] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 13:27:17,989] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 13:27:17,990] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 13:27:17,991] INFO Kafka store producer shut down (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:27:17,991] INFO Kafka store shut down complete (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:27:17,992] ERROR Unexpected exception in schema registry group processing thread (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
org.apache.kafka.common.errors.WakeupException
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.maybeTriggerWakeup(ConsumerNetworkClient.java:514)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:278)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:227)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator.poll(SchemaRegistryCoordinator.java:124)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector$1.run(KafkaGroupLeaderElector.java:202)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-12-07 13:28:12,415] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	debug = false
	host.name = 192.168.0.104
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	kafkastore.zk.session.timeout.ms = 30000
	leader.eligibility = true
	listeners = [http://0.0.0.0:8081]
	master.eligibility = null
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2020-12-07 13:28:12,460] INFO Logging initialized @525ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2020-12-07 13:28:12,468] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2020-12-07 13:28:12,535] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.ApplicationServer)
[2020-12-07 13:29:12,759] ERROR Error starting the schema registry (io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication)
io.confluent.kafka.schemaregistry.exceptions.SchemaRegistryException: Failed to get Kafka cluster ID
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.kafkaClusterId(KafkaSchemaRegistry.java:1277)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.<init>(KafkaSchemaRegistry.java:158)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.initSchemaRegistry(SchemaRegistryRestApplication.java:69)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.configureBaseApplication(SchemaRegistryRestApplication.java:88)
	at io.confluent.rest.Application.configureHandler(Application.java:254)
	at io.confluent.rest.ApplicationServer.doStart(ApplicationServer.java:227)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:72)
	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain.main(SchemaRegistryMain.java:43)
Caused by: java.util.concurrent.TimeoutException
	at org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.kafkaClusterId(KafkaSchemaRegistry.java:1275)
	... 7 more
[2020-12-07 13:29:29,565] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	debug = false
	host.name = 192.168.0.104
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	kafkastore.zk.session.timeout.ms = 30000
	leader.eligibility = true
	listeners = [http://0.0.0.0:8081]
	master.eligibility = null
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2020-12-07 13:29:29,608] INFO Logging initialized @512ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2020-12-07 13:29:29,615] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2020-12-07 13:29:29,683] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.ApplicationServer)
[2020-12-07 13:29:30,180] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-12-07 13:29:30,180] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-12-07 13:29:30,180] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-12-07 13:29:30,185] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:29:30,200] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:29:30,205] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:29:30,258] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 13:29:30,305] INFO Seeking to beginning for all partitions (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 13:29:30,306] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 13:29:30,307] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 13:29:30,403] INFO Wait to catch up until the offset at 12 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:29:30,410] INFO Reached offset at 12 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:29:30,411] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-12-07 13:29:30,461] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-47cfe9ba-66ba-43b7-9a90-7560574cb439', leaderIdentity=version=1,host=192.168.0.104,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2020-12-07 13:29:30,469] INFO Wait to catch up until the offset at 13 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:29:30,469] INFO Reached offset at 13 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:29:30,604] INFO jetty-9.4.30.v20200611; built: 2020-06-11T12:34:51.929Z; git: 271836e4c1f4612f12b7bb13ef5a92a927634b0d; jvm 1.8.0_265-b01 (org.eclipse.jetty.server.Server)
[2020-12-07 13:29:30,632] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2020-12-07 13:29:30,632] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2020-12-07 13:29:30,633] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session)
[2020-12-07 13:29:31,076] INFO HV000001: Hibernate Validator 6.1.2.Final (org.hibernate.validator.internal.util.Version)
[2020-12-07 13:29:31,274] INFO Started o.e.j.s.ServletContextHandler@76f4b65{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-12-07 13:29:31,285] INFO Started o.e.j.s.ServletContextHandler@34c01041{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-12-07 13:29:31,299] INFO Started NetworkTrafficServerConnector@43738a82{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-12-07 13:29:31,299] INFO Started @2205ms (org.eclipse.jetty.server.Server)
[2020-12-07 13:29:31,299] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2020-12-07 13:29:36,397] INFO 0:0:0:0:0:0:0:1 - - [07/Dec/2020:21:29:36 +0000] "GET /subjects HTTP/1.1" 200 49  156 (io.confluent.rest-utils.requests)
[2020-12-07 13:29:46,798] INFO 127.0.0.1 - - [07/Dec/2020:21:29:46 +0000] "GET / HTTP/1.1" 200 2  8 (io.confluent.rest-utils.requests)
[2020-12-07 13:30:10,422] INFO 127.0.0.1 - - [07/Dec/2020:21:30:10 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-12-07 13:30:24,450] INFO Deleting subject Kafka-value (io.confluent.kafka.schemaregistry.rest.resources.SubjectsResource)
[2020-12-07 13:30:24,453] INFO Wait to catch up until the offset at 13 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:30:24,453] INFO Reached offset at 13 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:30:24,459] INFO Wait to catch up until the offset at 14 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:30:24,462] INFO Reached offset at 14 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:30:24,465] INFO 0:0:0:0:0:0:0:1 - - [07/Dec/2020:21:30:24 +0000] "DELETE /subjects/Kafka-value HTTP/1.1" 200 3  21 (io.confluent.rest-utils.requests)
[2020-12-07 13:30:30,112] INFO 127.0.0.1 - - [07/Dec/2020:21:30:30 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:30:30,545] INFO Deleting subject Kafka-key (io.confluent.kafka.schemaregistry.rest.resources.SubjectsResource)
[2020-12-07 13:30:30,546] INFO Wait to catch up until the offset at 14 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:30:30,546] INFO Reached offset at 14 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:30:30,548] INFO Wait to catch up until the offset at 15 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:30:30,549] INFO Reached offset at 15 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:30:30,550] INFO 0:0:0:0:0:0:0:1 - - [07/Dec/2020:21:30:30 +0000] "DELETE /subjects/Kafka-key HTTP/1.1" 200 3  6 (io.confluent.rest-utils.requests)
[2020-12-07 13:30:53,036] INFO 127.0.0.1 - - [07/Dec/2020:21:30:53 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:31:11,871] INFO 127.0.0.1 - - [07/Dec/2020:21:31:11 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:31:31,564] INFO 127.0.0.1 - - [07/Dec/2020:21:31:31 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:31:49,602] INFO 127.0.0.1 - - [07/Dec/2020:21:31:49 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-12-07 13:32:09,932] INFO 127.0.0.1 - - [07/Dec/2020:21:32:09 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-12-07 13:32:27,078] INFO 127.0.0.1 - - [07/Dec/2020:21:32:27 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:32:50,502] INFO 127.0.0.1 - - [07/Dec/2020:21:32:50 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-12-07 13:32:52,209] INFO 0:0:0:0:0:0:0:1 - - [07/Dec/2020:21:32:52 +0000] "GET /subjects HTTP/1.1" 200 23  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:33:09,956] INFO Registering new schema: subject Kafka-value, version null, id null, type null (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2020-12-07 13:33:09,977] INFO Wait to catch up until the offset at 15 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:33:09,977] INFO Reached offset at 15 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:33:09,984] INFO Wait to catch up until the offset at 16 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:33:09,985] INFO Reached offset at 16 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:33:09,986] INFO Wait to catch up until the offset at 17 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:33:09,987] INFO Reached offset at 17 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:33:09,989] INFO 0:0:0:0:0:0:0:1 - - [07/Dec/2020:21:33:09 +0000] "POST /subjects/Kafka-value/versions HTTP/1.1" 200 13  53 (io.confluent.rest-utils.requests)
[2020-12-07 13:33:12,654] INFO 127.0.0.1 - - [07/Dec/2020:21:33:12 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:33:15,858] INFO 0:0:0:0:0:0:0:1 - - [07/Dec/2020:21:33:15 +0000] "GET /subjects HTTP/1.1" 200 37  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:33:31,044] INFO 127.0.0.1 - - [07/Dec/2020:21:33:31 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:33:33,786] INFO 0:0:0:0:0:0:0:1 - - [07/Dec/2020:21:33:33 +0000] "GET /subjects/Kafka-value/versions HTTP/1.1" 200 3  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:33:47,427] INFO 127.0.0.1 - - [07/Dec/2020:21:33:47 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:34:07,531] INFO 127.0.0.1 - - [07/Dec/2020:21:34:07 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:34:29,749] INFO 127.0.0.1 - - [07/Dec/2020:21:34:29 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:34:53,107] INFO 127.0.0.1 - - [07/Dec/2020:21:34:53 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:34:53,148] ERROR Request Failed with exception  (io.confluent.rest.exceptions.DebuggableExceptionMapper)
javax.ws.rs.NotFoundException: HTTP 404 Not Found
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:250)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:232)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.ServletContainer.serviceImpl(ServletContainer.java:386)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:561)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:502)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:439)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1618)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:549)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1610)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1369)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:489)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1580)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1284)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:717)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:501)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:272)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
	at java.lang.Thread.run(Thread.java:748)
[2020-12-07 13:34:53,152] INFO 0:0:0:0:0:0:0:1 - - [07/Dec/2020:21:34:53 +0000] "DELETE /ids/100002 HTTP/1.1" 404 49  7 (io.confluent.rest-utils.requests)
[2020-12-07 13:35:13,917] INFO 127.0.0.1 - - [07/Dec/2020:21:35:13 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:35:33,765] INFO 127.0.0.1 - - [07/Dec/2020:21:35:33 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:35:43,501] INFO Registering new schema: subject Kafka-value, version null, id null, type null (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2020-12-07 13:35:43,501] INFO Wait to catch up until the offset at 17 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:35:43,502] INFO Reached offset at 17 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:35:43,518] INFO Wait to catch up until the offset at 18 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:35:43,519] INFO Reached offset at 18 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:35:43,520] INFO 0:0:0:0:0:0:0:1 - - [07/Dec/2020:21:35:43 +0000] "POST /subjects/Kafka-value/versions HTTP/1.1" 200 13  21 (io.confluent.rest-utils.requests)
[2020-12-07 13:35:49,968] INFO 127.0.0.1 - - [07/Dec/2020:21:35:49 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:36:12,378] INFO 127.0.0.1 - - [07/Dec/2020:21:36:12 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:36:29,957] INFO 127.0.0.1 - - [07/Dec/2020:21:36:29 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:36:38,030] INFO Stopped NetworkTrafficServerConnector@43738a82{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-12-07 13:36:38,030] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2020-12-07 13:36:38,031] INFO Stopped o.e.j.s.ServletContextHandler@34c01041{/ws,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-12-07 13:36:38,036] INFO Stopped o.e.j.s.ServletContextHandler@76f4b65{/,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-12-07 13:36:38,037] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-12-07 13:36:38,037] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 13:36:38,038] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 13:36:38,038] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 13:36:38,039] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 13:36:38,040] INFO Kafka store producer shut down (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:36:38,040] INFO Kafka store shut down complete (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:36:38,040] ERROR Unexpected exception in schema registry group processing thread (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
org.apache.kafka.common.errors.WakeupException
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.maybeTriggerWakeup(ConsumerNetworkClient.java:514)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:278)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:227)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator.poll(SchemaRegistryCoordinator.java:124)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector$1.run(KafkaGroupLeaderElector.java:202)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-12-07 13:36:41,408] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	debug = false
	host.name = 192.168.0.104
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	kafkastore.zk.session.timeout.ms = 30000
	leader.eligibility = true
	listeners = [http://0.0.0.0:8081]
	master.eligibility = null
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2020-12-07 13:36:41,454] INFO Logging initialized @570ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2020-12-07 13:36:41,462] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2020-12-07 13:36:41,530] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.ApplicationServer)
[2020-12-07 13:36:42,045] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-12-07 13:36:42,045] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-12-07 13:36:42,045] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-12-07 13:36:42,049] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:36:42,061] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:36:42,066] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:36:42,117] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 13:36:42,159] INFO Seeking to beginning for all partitions (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 13:36:42,160] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 13:36:42,161] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 13:36:42,229] INFO Wait to catch up until the offset at 19 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:36:42,266] INFO Reached offset at 19 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:36:42,267] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-12-07 13:36:42,297] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-1379c06d-bb46-4218-830d-b31bcecd81d6', leaderIdentity=version=1,host=192.168.0.104,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2020-12-07 13:36:42,304] INFO Wait to catch up until the offset at 20 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:36:42,305] INFO Reached offset at 20 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:36:42,431] INFO jetty-9.4.30.v20200611; built: 2020-06-11T12:34:51.929Z; git: 271836e4c1f4612f12b7bb13ef5a92a927634b0d; jvm 1.8.0_265-b01 (org.eclipse.jetty.server.Server)
[2020-12-07 13:36:42,460] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2020-12-07 13:36:42,460] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2020-12-07 13:36:42,461] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session)
[2020-12-07 13:36:42,905] INFO HV000001: Hibernate Validator 6.1.2.Final (org.hibernate.validator.internal.util.Version)
[2020-12-07 13:36:43,104] INFO Started o.e.j.s.ServletContextHandler@76f4b65{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-12-07 13:36:43,117] INFO Started o.e.j.s.ServletContextHandler@34c01041{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-12-07 13:36:43,137] INFO Started NetworkTrafficServerConnector@43738a82{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-12-07 13:36:43,137] INFO Started @2255ms (org.eclipse.jetty.server.Server)
[2020-12-07 13:36:43,137] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2020-12-07 13:36:51,982] INFO 127.0.0.1 - - [07/Dec/2020:21:36:51 +0000] "GET / HTTP/1.1" 200 2  91 (io.confluent.rest-utils.requests)
[2020-12-07 13:36:52,441] INFO Registering new schema: subject Kafka-value, version null, id null, type null (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2020-12-07 13:36:52,461] INFO Wait to catch up until the offset at 20 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:36:52,461] INFO Reached offset at 20 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:36:52,480] INFO Wait to catch up until the offset at 21 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:36:52,480] INFO Reached offset at 21 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:36:52,483] INFO 0:0:0:0:0:0:0:1 - - [07/Dec/2020:21:36:52 +0000] "POST /subjects/Kafka-value/versions HTTP/1.1" 200 13  84 (io.confluent.rest-utils.requests)
[2020-12-07 13:37:12,817] INFO 127.0.0.1 - - [07/Dec/2020:21:37:12 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-12-07 13:37:34,374] INFO 127.0.0.1 - - [07/Dec/2020:21:37:34 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:37:55,370] INFO 127.0.0.1 - - [07/Dec/2020:21:37:55 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-12-07 13:38:15,611] INFO 127.0.0.1 - - [07/Dec/2020:21:38:15 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 13:38:38,658] INFO 127.0.0.1 - - [07/Dec/2020:21:38:38 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-12-07 13:38:56,523] INFO 127.0.0.1 - - [07/Dec/2020:21:38:56 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:39:14,156] INFO 127.0.0.1 - - [07/Dec/2020:21:39:14 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-12-07 13:39:32,913] INFO 127.0.0.1 - - [07/Dec/2020:21:39:32 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-12-07 13:39:54,269] INFO 127.0.0.1 - - [07/Dec/2020:21:39:54 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-12-07 13:40:16,598] INFO 127.0.0.1 - - [07/Dec/2020:21:40:16 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 13:40:39,467] INFO 127.0.0.1 - - [07/Dec/2020:21:40:39 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 13:40:44,691] INFO Stopped NetworkTrafficServerConnector@43738a82{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-12-07 13:40:44,692] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2020-12-07 13:40:44,693] INFO Stopped o.e.j.s.ServletContextHandler@34c01041{/ws,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-12-07 13:40:44,697] INFO Stopped o.e.j.s.ServletContextHandler@76f4b65{/,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-12-07 13:40:44,698] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-12-07 13:40:44,699] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 13:40:44,699] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 13:40:44,699] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 13:40:44,700] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 13:40:44,701] INFO Kafka store producer shut down (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:40:44,701] INFO Kafka store shut down complete (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 13:40:44,702] ERROR Unexpected exception in schema registry group processing thread (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
org.apache.kafka.common.errors.WakeupException
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.maybeTriggerWakeup(ConsumerNetworkClient.java:514)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:278)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:227)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator.poll(SchemaRegistryCoordinator.java:124)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector$1.run(KafkaGroupLeaderElector.java:202)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-12-07 14:15:54,925] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	debug = true
	host.name = 192.168.0.104
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	kafkastore.zk.session.timeout.ms = 30000
	leader.eligibility = true
	listeners = [http://0.0.0.0:8081]
	master.eligibility = null
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2020-12-07 14:15:54,985] INFO Logging initialized @768ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2020-12-07 14:15:54,995] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2020-12-07 14:15:55,070] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.ApplicationServer)
[2020-12-07 14:15:55,666] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-12-07 14:15:55,666] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-12-07 14:15:55,667] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-12-07 14:15:55,670] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 14:15:55,683] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 14:15:55,687] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 14:15:55,754] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 14:15:55,800] INFO Seeking to beginning for all partitions (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 14:15:55,801] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 14:15:55,802] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 14:15:55,878] INFO Wait to catch up until the offset at 22 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 14:15:55,919] INFO Reached offset at 22 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 14:15:55,921] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-12-07 14:15:55,951] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-68c467f0-dcd1-463f-9011-11f17221fe53', leaderIdentity=version=1,host=192.168.0.104,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2020-12-07 14:15:55,959] INFO Wait to catch up until the offset at 23 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 14:15:55,960] INFO Reached offset at 23 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 14:15:56,120] INFO jetty-9.4.30.v20200611; built: 2020-06-11T12:34:51.929Z; git: 271836e4c1f4612f12b7bb13ef5a92a927634b0d; jvm 1.8.0_265-b01 (org.eclipse.jetty.server.Server)
[2020-12-07 14:15:56,150] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2020-12-07 14:15:56,150] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2020-12-07 14:15:56,152] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session)
[2020-12-07 14:15:56,647] INFO HV000001: Hibernate Validator 6.1.2.Final (org.hibernate.validator.internal.util.Version)
[2020-12-07 14:15:56,861] INFO Started o.e.j.s.ServletContextHandler@76f4b65{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-12-07 14:15:56,872] INFO Started o.e.j.s.ServletContextHandler@34c01041{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-12-07 14:15:56,886] INFO Started NetworkTrafficServerConnector@43738a82{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-12-07 14:15:56,886] INFO Started @2671ms (org.eclipse.jetty.server.Server)
[2020-12-07 14:15:56,886] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2020-12-07 14:16:03,919] INFO 127.0.0.1 - - [07/Dec/2020:22:16:03 +0000] "GET / HTTP/1.1" 200 2  97 (io.confluent.rest-utils.requests)
[2020-12-07 14:16:07,080] INFO 0:0:0:0:0:0:0:1 - - [07/Dec/2020:22:16:07 +0000] "GET /subjects HTTP/1.1" 200 37  75 (io.confluent.rest-utils.requests)
[2020-12-07 14:16:22,750] INFO 127.0.0.1 - - [07/Dec/2020:22:16:22 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-12-07 14:16:45,465] INFO 127.0.0.1 - - [07/Dec/2020:22:16:45 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:16:54,761] INFO Registering new schema: subject Kafka-value, version null, id null, type null (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2020-12-07 14:16:54,786] INFO Wait to catch up until the offset at 23 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 14:16:54,786] INFO Reached offset at 23 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 14:16:54,811] INFO Wait to catch up until the offset at 24 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 14:16:54,811] INFO Reached offset at 24 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 14:16:54,816] INFO 0:0:0:0:0:0:0:1 - - [07/Dec/2020:22:16:54 +0000] "POST /subjects/Kafka-value/versions HTTP/1.1" 200 13  80 (io.confluent.rest-utils.requests)
[2020-12-07 14:17:07,305] INFO 127.0.0.1 - - [07/Dec/2020:22:17:07 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-12-07 14:17:31,016] INFO 127.0.0.1 - - [07/Dec/2020:22:17:31 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:17:49,550] INFO 127.0.0.1 - - [07/Dec/2020:22:17:49 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:18:12,016] INFO 127.0.0.1 - - [07/Dec/2020:22:18:12 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:18:28,376] INFO 127.0.0.1 - - [07/Dec/2020:22:18:28 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:18:48,544] INFO 127.0.0.1 - - [07/Dec/2020:22:18:48 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:19:08,210] INFO 127.0.0.1 - - [07/Dec/2020:22:19:08 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:19:29,618] INFO 127.0.0.1 - - [07/Dec/2020:22:19:29 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:19:48,927] INFO 127.0.0.1 - - [07/Dec/2020:22:19:48 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:20:06,067] INFO 127.0.0.1 - - [07/Dec/2020:22:20:06 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:20:23,699] INFO 127.0.0.1 - - [07/Dec/2020:22:20:23 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:20:40,922] INFO 127.0.0.1 - - [07/Dec/2020:22:20:40 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:21:02,963] INFO 127.0.0.1 - - [07/Dec/2020:22:21:02 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:21:21,097] INFO 127.0.0.1 - - [07/Dec/2020:22:21:21 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:21:42,762] INFO 127.0.0.1 - - [07/Dec/2020:22:21:42 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:22:04,973] INFO 127.0.0.1 - - [07/Dec/2020:22:22:04 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:22:27,994] INFO 127.0.0.1 - - [07/Dec/2020:22:22:27 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:22:51,317] INFO 127.0.0.1 - - [07/Dec/2020:22:22:51 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:23:08,124] INFO 127.0.0.1 - - [07/Dec/2020:22:23:08 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:23:24,701] INFO 127.0.0.1 - - [07/Dec/2020:22:23:24 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:23:47,375] INFO 127.0.0.1 - - [07/Dec/2020:22:23:47 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:24:07,680] INFO 127.0.0.1 - - [07/Dec/2020:22:24:07 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:24:26,642] INFO 127.0.0.1 - - [07/Dec/2020:22:24:26 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:24:48,064] INFO 127.0.0.1 - - [07/Dec/2020:22:24:48 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:25:10,751] INFO 127.0.0.1 - - [07/Dec/2020:22:25:10 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:25:31,638] INFO 127.0.0.1 - - [07/Dec/2020:22:25:31 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:25:48,780] INFO 127.0.0.1 - - [07/Dec/2020:22:25:48 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:26:11,017] INFO 127.0.0.1 - - [07/Dec/2020:22:26:11 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:26:31,731] INFO 127.0.0.1 - - [07/Dec/2020:22:26:31 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:26:50,853] INFO 127.0.0.1 - - [07/Dec/2020:22:26:50 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:27:10,827] INFO 127.0.0.1 - - [07/Dec/2020:22:27:10 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:27:28,748] INFO 127.0.0.1 - - [07/Dec/2020:22:27:28 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:27:47,489] INFO 127.0.0.1 - - [07/Dec/2020:22:27:47 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:28:06,494] INFO 127.0.0.1 - - [07/Dec/2020:22:28:06 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:28:24,255] INFO 127.0.0.1 - - [07/Dec/2020:22:28:24 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:28:41,400] INFO 127.0.0.1 - - [07/Dec/2020:22:28:41 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:28:58,993] INFO 127.0.0.1 - - [07/Dec/2020:22:28:58 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:29:17,272] INFO 127.0.0.1 - - [07/Dec/2020:22:29:17 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-12-07 14:29:35,809] INFO 127.0.0.1 - - [07/Dec/2020:22:29:35 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:29:56,478] INFO 127.0.0.1 - - [07/Dec/2020:22:29:56 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:30:13,785] INFO 127.0.0.1 - - [07/Dec/2020:22:30:13 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:30:30,959] INFO 127.0.0.1 - - [07/Dec/2020:22:30:30 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:30:47,581] INFO 127.0.0.1 - - [07/Dec/2020:22:30:47 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:31:07,800] INFO 127.0.0.1 - - [07/Dec/2020:22:31:07 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:31:30,503] INFO 127.0.0.1 - - [07/Dec/2020:22:31:30 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:31:50,424] INFO 127.0.0.1 - - [07/Dec/2020:22:31:50 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:32:09,014] INFO 127.0.0.1 - - [07/Dec/2020:22:32:09 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:32:28,998] INFO 127.0.0.1 - - [07/Dec/2020:22:32:28 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:32:47,072] INFO 127.0.0.1 - - [07/Dec/2020:22:32:47 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:33:05,746] INFO 127.0.0.1 - - [07/Dec/2020:22:33:05 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:33:27,580] INFO 127.0.0.1 - - [07/Dec/2020:22:33:27 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:33:51,179] INFO 127.0.0.1 - - [07/Dec/2020:22:33:51 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:34:13,538] INFO 127.0.0.1 - - [07/Dec/2020:22:34:13 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:34:36,450] INFO 127.0.0.1 - - [07/Dec/2020:22:34:36 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:34:55,414] INFO 127.0.0.1 - - [07/Dec/2020:22:34:55 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:35:19,019] INFO 127.0.0.1 - - [07/Dec/2020:22:35:19 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:35:42,941] INFO 127.0.0.1 - - [07/Dec/2020:22:35:42 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:36:05,892] INFO 127.0.0.1 - - [07/Dec/2020:22:36:05 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:36:28,617] INFO 127.0.0.1 - - [07/Dec/2020:22:36:28 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-12-07 14:36:49,486] INFO 127.0.0.1 - - [07/Dec/2020:22:36:49 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:37:10,609] INFO 127.0.0.1 - - [07/Dec/2020:22:37:10 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:37:30,659] INFO 127.0.0.1 - - [07/Dec/2020:22:37:30 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:37:52,032] INFO 127.0.0.1 - - [07/Dec/2020:22:37:52 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:38:08,746] INFO 127.0.0.1 - - [07/Dec/2020:22:38:08 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:38:28,313] INFO 127.0.0.1 - - [07/Dec/2020:22:38:28 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:38:52,119] INFO 127.0.0.1 - - [07/Dec/2020:22:38:52 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:39:10,295] INFO 127.0.0.1 - - [07/Dec/2020:22:39:10 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:39:29,236] INFO 127.0.0.1 - - [07/Dec/2020:22:39:29 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:39:47,524] INFO 127.0.0.1 - - [07/Dec/2020:22:39:47 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:40:05,501] INFO 127.0.0.1 - - [07/Dec/2020:22:40:05 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:40:23,022] INFO 127.0.0.1 - - [07/Dec/2020:22:40:23 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:40:45,413] INFO 127.0.0.1 - - [07/Dec/2020:22:40:45 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:41:02,492] INFO 127.0.0.1 - - [07/Dec/2020:22:41:02 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:41:23,714] INFO 127.0.0.1 - - [07/Dec/2020:22:41:23 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:41:39,850] INFO 127.0.0.1 - - [07/Dec/2020:22:41:39 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:42:01,667] INFO 127.0.0.1 - - [07/Dec/2020:22:42:01 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:42:23,335] INFO 127.0.0.1 - - [07/Dec/2020:22:42:23 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:42:42,594] INFO 127.0.0.1 - - [07/Dec/2020:22:42:42 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:43:01,879] INFO 127.0.0.1 - - [07/Dec/2020:22:43:01 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:43:21,313] INFO 127.0.0.1 - - [07/Dec/2020:22:43:21 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-12-07 14:43:41,896] INFO 127.0.0.1 - - [07/Dec/2020:22:43:41 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:44:04,722] INFO 127.0.0.1 - - [07/Dec/2020:22:44:04 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:44:22,732] INFO 127.0.0.1 - - [07/Dec/2020:22:44:22 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:44:42,015] INFO 127.0.0.1 - - [07/Dec/2020:22:44:42 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:44:59,496] INFO 127.0.0.1 - - [07/Dec/2020:22:44:59 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:45:16,599] INFO 127.0.0.1 - - [07/Dec/2020:22:45:16 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:45:34,978] INFO 127.0.0.1 - - [07/Dec/2020:22:45:34 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:45:56,995] INFO 127.0.0.1 - - [07/Dec/2020:22:45:56 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:46:13,888] INFO 127.0.0.1 - - [07/Dec/2020:22:46:13 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:46:30,469] INFO 127.0.0.1 - - [07/Dec/2020:22:46:30 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:46:54,419] INFO 127.0.0.1 - - [07/Dec/2020:22:46:54 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:47:13,332] INFO 127.0.0.1 - - [07/Dec/2020:22:47:13 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:47:32,258] INFO 127.0.0.1 - - [07/Dec/2020:22:47:32 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:47:49,040] INFO 127.0.0.1 - - [07/Dec/2020:22:47:49 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:48:08,031] INFO 127.0.0.1 - - [07/Dec/2020:22:48:08 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:48:26,545] INFO 127.0.0.1 - - [07/Dec/2020:22:48:26 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:48:45,048] INFO 127.0.0.1 - - [07/Dec/2020:22:48:45 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:49:08,122] INFO 127.0.0.1 - - [07/Dec/2020:22:49:08 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:49:26,232] INFO 127.0.0.1 - - [07/Dec/2020:22:49:26 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:49:49,284] INFO 127.0.0.1 - - [07/Dec/2020:22:49:49 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:50:10,796] INFO 127.0.0.1 - - [07/Dec/2020:22:50:10 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:50:31,917] INFO 127.0.0.1 - - [07/Dec/2020:22:50:31 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:50:52,762] INFO 127.0.0.1 - - [07/Dec/2020:22:50:52 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:51:09,631] INFO 127.0.0.1 - - [07/Dec/2020:22:51:09 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:51:25,680] INFO 127.0.0.1 - - [07/Dec/2020:22:51:25 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:51:41,793] INFO 127.0.0.1 - - [07/Dec/2020:22:51:41 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:52:05,455] INFO 127.0.0.1 - - [07/Dec/2020:22:52:05 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:52:25,811] INFO 127.0.0.1 - - [07/Dec/2020:22:52:25 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:52:49,786] INFO 127.0.0.1 - - [07/Dec/2020:22:52:49 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:53:08,730] INFO 127.0.0.1 - - [07/Dec/2020:22:53:08 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:53:25,566] INFO 127.0.0.1 - - [07/Dec/2020:22:53:25 +0000] "GET / HTTP/1.1" 200 2  2 (io.confluent.rest-utils.requests)
[2020-12-07 14:53:42,879] INFO 127.0.0.1 - - [07/Dec/2020:22:53:42 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:54:02,279] INFO 127.0.0.1 - - [07/Dec/2020:22:54:02 +0000] "GET / HTTP/1.1" 200 2  1 (io.confluent.rest-utils.requests)
[2020-12-07 14:54:08,777] INFO Stopped NetworkTrafficServerConnector@43738a82{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-12-07 14:54:08,778] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2020-12-07 14:54:08,779] INFO Stopped o.e.j.s.ServletContextHandler@34c01041{/ws,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-12-07 14:54:08,785] INFO Stopped o.e.j.s.ServletContextHandler@76f4b65{/,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-12-07 14:54:08,786] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-12-07 14:54:08,787] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 14:54:08,787] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 14:54:08,787] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 14:54:08,789] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 14:54:08,790] INFO Kafka store producer shut down (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 14:54:08,790] INFO Kafka store shut down complete (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 14:54:08,791] ERROR Unexpected exception in schema registry group processing thread (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
org.apache.kafka.common.errors.WakeupException
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.maybeTriggerWakeup(ConsumerNetworkClient.java:514)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:278)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:227)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator.poll(SchemaRegistryCoordinator.java:124)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector$1.run(KafkaGroupLeaderElector.java:202)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-12-07 15:08:40,382] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	debug = true
	host.name = 192.168.0.104
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.protocol = http
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	kafkastore.zk.session.timeout.ms = 30000
	leader.eligibility = true
	listeners = [http://0.0.0.0:8081]
	master.eligibility = null
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	port = 8081
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	schema.registry.zk.namespace = schema_registry
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
	zookeeper.set.acl = false
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2020-12-07 15:08:40,423] INFO Logging initialized @623ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2020-12-07 15:08:40,431] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2020-12-07 15:08:40,503] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.ApplicationServer)
[2020-12-07 15:08:40,980] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-12-07 15:08:40,981] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-12-07 15:08:40,981] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-12-07 15:08:40,984] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 15:08:40,996] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 15:08:41,001] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 15:08:41,052] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 15:08:41,093] INFO Seeking to beginning for all partitions (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 15:08:41,093] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 15:08:41,095] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 15:08:41,166] INFO Wait to catch up until the offset at 33 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 15:08:41,204] INFO Reached offset at 33 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 15:08:41,204] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-12-07 15:08:41,232] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-9f8f98fb-b716-472b-b9a3-b9ab04784b06', leaderIdentity=version=1,host=192.168.0.104,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2020-12-07 15:08:41,239] INFO Wait to catch up until the offset at 34 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 15:08:41,240] INFO Reached offset at 34 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 15:08:41,361] INFO jetty-9.4.30.v20200611; built: 2020-06-11T12:34:51.929Z; git: 271836e4c1f4612f12b7bb13ef5a92a927634b0d; jvm 1.8.0_265-b01 (org.eclipse.jetty.server.Server)
[2020-12-07 15:08:41,390] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2020-12-07 15:08:41,390] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2020-12-07 15:08:41,392] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session)
[2020-12-07 15:08:41,822] INFO HV000001: Hibernate Validator 6.1.2.Final (org.hibernate.validator.internal.util.Version)
[2020-12-07 15:08:42,018] INFO Started o.e.j.s.ServletContextHandler@76f4b65{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-12-07 15:08:42,029] INFO Started o.e.j.s.ServletContextHandler@34c01041{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-12-07 15:08:42,042] INFO Started NetworkTrafficServerConnector@43738a82{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-12-07 15:08:42,042] INFO Started @2243ms (org.eclipse.jetty.server.Server)
[2020-12-07 15:08:42,042] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2020-12-07 15:08:54,057] INFO 127.0.0.1 - - [07/Dec/2020:23:08:53 +0000] "GET / HTTP/1.1" 200 2  83 (io.confluent.rest-utils.requests)
[2020-12-07 15:08:58,417] INFO Registering new schema: subject Kafka-key, version null, id null, type null (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2020-12-07 15:08:58,437] INFO Wait to catch up until the offset at 34 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 15:08:58,437] INFO Reached offset at 34 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 15:08:58,445] INFO Wait to catch up until the offset at 35 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 15:08:58,445] INFO Reached offset at 35 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 15:08:58,448] INFO 0:0:0:0:0:0:0:1 - - [07/Dec/2020:23:08:58 +0000] "POST /subjects/Kafka-key/versions HTTP/1.1" 200 13  78 (io.confluent.rest-utils.requests)
[2020-12-07 15:09:14,122] INFO 127.0.0.1 - - [07/Dec/2020:23:09:14 +0000] "GET / HTTP/1.1" 200 2  3 (io.confluent.rest-utils.requests)
[2020-12-07 15:09:21,469] INFO Stopped NetworkTrafficServerConnector@43738a82{HTTP/1.1, (http/1.1)}{0.0.0.0:8081} (org.eclipse.jetty.server.AbstractConnector)
[2020-12-07 15:09:21,470] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2020-12-07 15:09:21,471] INFO Stopped o.e.j.s.ServletContextHandler@34c01041{/ws,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-12-07 15:09:21,476] INFO Stopped o.e.j.s.ServletContextHandler@76f4b65{/,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2020-12-07 15:09:21,477] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2020-12-07 15:09:21,478] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 15:09:21,478] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 15:09:21,478] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 15:09:21,480] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2020-12-07 15:09:21,481] INFO Kafka store producer shut down (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 15:09:21,481] INFO Kafka store shut down complete (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2020-12-07 15:09:21,482] ERROR Unexpected exception in schema registry group processing thread (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
org.apache.kafka.common.errors.WakeupException
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.maybeTriggerWakeup(ConsumerNetworkClient.java:514)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:278)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:227)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator.poll(SchemaRegistryCoordinator.java:124)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector$1.run(KafkaGroupLeaderElector.java:202)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
